{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2ae6cc6-14c1-43dc-a2c2-f0208e028ea1",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "This will break down the file in the following steps:\n",
    "1. Each \"END GO\" is treated as a unique SQL\n",
    "2. look at each line and remove comments (--)\n",
    "3. Look at comments block then remove (/* */)\n",
    "4. Look for keywords like FROM, JOIN , UPDATE, INTO, CREATE TABLE then grab the next word (Database.Schema.Name or Schema.Name)\n",
    "    (not necessary to find relationships, so all will be just using the RELY_ON relationship.)\n",
    "5. Concatenating into a single dataframe and output to CSV\n",
    "6. Ingest into Graph Database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4fde14e-4939-4103-8040-4d307323e713",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fdce299-6526-4936-9565-532c3cc4dd89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import nbformat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09da9069-8511-47dd-b882-0766cdbac486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_script_view =  1.INPUT/DATAWAREHOUSE/ViewScript.sql\n",
      "input_script_sp =  1.INPUT/DATAWAREHOUSE/SPsScript.sql\n",
      "input_script_table =  1.INPUT/DATAWAREHOUSE/tableScript.sql\n",
      "graph_ingestion_view =  3.OUTPUT_GRAPH/graph_input_vw.csv\n",
      "graph_ingestion_sp =  3.OUTPUT_GRAPH/graph_input_sp.csv\n",
      "graph_ingestion_sp2 =  3.OUTPUT_GRAPH/graph_input_sp2.csv\n",
      "graph_ingestion_table =  3.OUTPUT_GRAPH/graph_input_table.csv\n"
     ]
    }
   ],
   "source": [
    "%run \"0_Configuration.ipynb\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8fe0ad-7d7b-4c87-8abf-f43e3e887e97",
   "metadata": {},
   "source": [
    "### Import Files\n",
    "#### We will use 1 files from 1.INPUT folder\n",
    "1A. Stored Procedure SQL files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a3f35d1-b5ba-4949-9e8e-dcefe23a8a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_raw_sql_view(sql_input, regex_str):\n",
    "    str_found  = re.findall(regex_str, sql_input)\n",
    "  #  print(\"viewname found\", str_found)\n",
    "    df = pd.DataFrame (str_found, columns = ['SP_SCHEMA', 'SP_NAME'])\n",
    "    df['SYNTAX'] = sql_input\n",
    "    return df\n",
    "\n",
    "\n",
    "def final_table_name_cleansing(text):\n",
    "    if text==text:\n",
    "            input_str = text.replace('FROM', '').replace('JOIN', '').replace(']', '').replace('[', '').replace(' ', '')\n",
    "    else:\n",
    "        input_str = \"\"\n",
    "    return input_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca03cf36-36f2-44b6-aa73-4e808c06e66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open and read the file as a single buffer\n",
    "fd = open(input_script_sp, 'r', encoding=\"utf-16\")\n",
    "sqlFile = fd.read()\n",
    "fd.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04b1a662-6bea-4fc3-9bea-9bdbb780a171",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#This convert the raw SQL file into a Dataframe for our later REGEX manipulation\n",
    "\n",
    "df = pd.DataFrame()\n",
    "i= 1\n",
    "\n",
    "for sql_statement in re.split(r'CREATE\\s+PROC', sqlFile):\n",
    "    i = i + 1\n",
    "    concat_sql = \"\"\n",
    "    sql_statement = sql_statement.upper()\n",
    "    #print(i, sql_statement)\n",
    "    for line in sql_statement.split(\"\\n\"):\n",
    "        #Remove anythign on the right of the comment\n",
    "        if not \"/\" in line: \n",
    "            q = line.split(\"--\")[0]\n",
    "            concat_sql = concat_sql + \" \" + q\n",
    "       # print(line)\n",
    "        \n",
    "\n",
    "    concat_sql = concat_sql.replace('\\t', ' ').replace(\"  \", \" \").replace(\"  \", \" \").replace(\"  \", \" \").replace(\"  \", \" \").replace(\"  \", \" \")\n",
    "    concat_sql = re.sub(r\"\\/\\*[\\s\\S]*?\\*\\/|([^:]|^)\\/\\/.*$\", \"\", concat_sql)\n",
    "    \n",
    "    #print(concat_sql)\n",
    "    \n",
    "    df = pd.concat([df, read_raw_sql_view(\"CREATE PROC \" + concat_sql, r\"(?ims)\\b(?:CREATE\\s+PROC)\\s+(\\[?\\w+\\]?)\\.(\\[?\\w+\\]?)\")], ignore_index=True )\n",
    "\n",
    "df['SP_SCHEMA']=df['SP_SCHEMA'].apply(lambda x: final_table_name_cleansing(x))\n",
    "df['SP_NAME']=df['SP_NAME'].apply(lambda x: final_table_name_cleansing(x))\n",
    "\n",
    "df.apply(lambda x: x.astype(str).str.upper())\n",
    "df['last_element'] =  df['SP_NAME'].str.split('_').str[-1]\n",
    "\n",
    "\n",
    "# This is where you set logics to exclude certain SP by name\n",
    "exclusion_list = ['TMP', 'TEMP', \n",
    "                  'BCK', 'BKP', 'BACK',\n",
    "                  'TEST', 'RSV']\n",
    "\n",
    "exclusion_list_v2 = [\"_\" + sub for sub in exclusion_list]\n",
    "\n",
    "df['EXCLUSION_v1'] = df['SP_NAME'].apply(lambda x: any([k in x for k in exclusion_list_v2]))\n",
    "df['EXCLUSION_v2'] = df['last_element'].apply(lambda x: any([k in x for k in exclusion_list]))\n",
    "\n",
    "def find_suffix_digits(stringInput):\n",
    "    return bool(re.search(r\"_[\\d]{4,8}$\", stringInput))\n",
    "\n",
    "df['EXCLUSION_digit'] = df['SP_SCHEMA'].apply(lambda x: find_suffix_digits(x))\n",
    "df['EXCLUSION_utils'] = df.SP_SCHEMA.str.contains(\"util\")\n",
    "\n",
    "df['EXCLUSION'] = df.EXCLUSION_v1 | df.EXCLUSION_v2 | df.EXCLUSION_digit | df.EXCLUSION_utils\n",
    "\n",
    "df = df[['SP_SCHEMA', 'SP_NAME', 'SYNTAX', 'EXCLUSION']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222d24b3-d5f5-47a1-9074-5f5b40604bd2",
   "metadata": {},
   "source": [
    "filterlist = ['TCDT_TO_TRANSFERENCE_LOG_RAW',\n",
    "    'PF_HKMN_SP_DIM_TABLE',\n",
    "    'PF_HKWE_SP_BASIC_CALC_METRICS',\n",
    "    'PF_HKWE_SP_DIM_TX_DETAIL',\n",
    "    'PF_HKWE_SP_DIM_TX_ITEM',\n",
    "    'PF_HKWE_SP_DIM_TX_PROMOTION',\n",
    "    'PF_HKWE_SP_DIM_TX_STORE',\n",
    "    'PF_HKWE_SP_DIM_TX_UPSCALE',\n",
    "    'PF_HKWE_SP_HIERARCHY_DASHBOARD',\n",
    "    'PF_HKWE_SP_INSERT_MEM_CNT_YEARLY_L13',\n",
    "    'PF_HKWE_SP_INSERT_MEM_CNT_YEARLY_L52',\n",
    "    'PF_HKWE_SP_INSERT_MEM_CNT_YEARLY_TW_L4W',\n",
    "    'PF_HKWE_SP_STG_ALL_PERIODE',\n",
    "    'PF_HKWE_SP_STG_MEM_CNT_YEARLY_YTD',\n",
    "    'PF_HKWE_SP_STG_MONTHLY',\n",
    "    'PF_HKWE_SP_STG_MONTHLY_SEGMENT',\n",
    "    'PF_HKWE_SP_STG_SEGMENT_BASE',\n",
    "    'PF_HKWE_SP_STG_WEEKLY',\n",
    "    'PF_HKWE_SP_STG_YEARLY',\n",
    "    'PF_HKWE_SP_STG_YEARLY_SEGMENT',\n",
    "    'PF_HKWE_SP_TX_FINAL']\n",
    "\n",
    "filterlist = ['TCDT_TO_TRANSFERENCE_LOG_RAW']\n",
    "\n",
    "df = df[df['SP_NAME'].isin(filterlist)]\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5be866-b033-4a3f-b712-c45c037b3524",
   "metadata": {},
   "source": [
    "#### This is what the output dataframe should look like to feed into the Regex Engine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c70ea8-27d7-4d37-9502-fec453f40ca5",
   "metadata": {},
   "source": [
    "### 2. Main ETL Codes\n",
    "#### Now using REGEX to identify the SP-Table relationships\n",
    "#### We will use only the SP Dataframe we got earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82fcb37d-6897-4cf4-a121-ab211c976ca4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "#This function is used to loop complex pattern like \"INSERT INTO FROM SELECT * FROM xxx\"\n",
    "#Since there can be multiple SELECT FROM tables, Will start from the most outer shell, then move inner\n",
    "#If There is a CREATE TABLE/INSERT TABLE statement, then will get from there\n",
    "def regex_part_analyser(sql_input, regex_type, regex_str, df_master):\n",
    "    str_found  = re.findall(regex_str, sql_input)\n",
    "    str_cat=str_found\n",
    "\n",
    "    df = pd.DataFrame (str_cat, columns = ['TABLE_FULL_NAME'])\n",
    "    df['REGEX_TYPE'] = regex_type\n",
    "    return df\n",
    "\n",
    "def regex_manipulation(sql_input, regex_type, regex_str, opt_df=None, opt_col=None):\n",
    "    output = re.findall(regex_str, sql_input)\n",
    "    output = list(dict.fromkeys(output))\n",
    "    \n",
    "    if opt_df is not None:\n",
    "            output = [x for x in output if x not in opt_df[opt_df.REGEX_TYPE==opt_col]['TABLE_FULL_NAME'].tolist()]\n",
    "\n",
    "    df = pd.DataFrame (output, columns = ['TABLE_FULL_NAME'])\n",
    "    df['REGEX_TYPE'] = regex_type\n",
    "    \n",
    "    return df\n",
    "\n",
    "def isNaN(string):\n",
    "    return string != string\n",
    "\n",
    "\n",
    "\n",
    "def regex_main_analyser( index, rowInput, sql_Input):\n",
    "    \n",
    "    # remove the /* */ comments\n",
    "    q = re.sub(r\"/\\*[^*]*\\*+(?:[^*/][^*]*\\*+)*/\", \"\", sql_Input)\n",
    "\n",
    "    #remove the */ and /* comments\n",
    "    q  = re.sub(r\"[^*]*\\*+(?:[^*/][^*]*\\*+)*/\", \"\", q)\n",
    "    q  = re.sub(r\"\\/\\*[^,]*$\", \"\", q)\n",
    "    q  = q.replace('\"','')\n",
    "    q  = q.upper()\n",
    "    df = pd.DataFrame()\n",
    "    #print(q)\n",
    "    \n",
    "    #Splitting the Source Code into multiple SQL statement by ';'\n",
    "    list_sql_statement = q.split(';')\n",
    "    \n",
    "    \n",
    "    for sql_statement in list_sql_statement:\n",
    "\n",
    "        #print(sql_statement)\n",
    "        #1 components TABLE string database.schema.table\n",
    "        df = pd.concat([df, regex_part_analyser(sql_statement, \"SELECT_FROM\", \n",
    "                                                         r\"(?ims)\\b(?:FROM|JOIN)\\s+([\\[]?[\\w-]+(?:[\\]]?\\.[\\[]?\\w+[\\]]?))(?:,|\\)|;| |$){1}\", df)])\n",
    "      \n",
    "        df = pd.concat([df, regex_part_analyser(sql_statement, \"SELECT_FROM\", \n",
    "                                                         r\"(?ims)\\b(?:FROM|JOIN)\\s+(?:[\\[]?[\\w-]+(?:[\\]]?\\.[\\[]?\\w+[\\]]?\\.[\\[]?\\w+[\\]]?))\\s*\\w*\\s*,\\s*([\\[]?[\\w-]+(?:[\\]]?\\.[\\[]?\\w+[\\]]?\\.[\\[]?\\w+[\\]]?))(?:,|\\)|;| |$){1}\", df)])   \n",
    "    \n",
    "    \n",
    "        df = pd.concat([df, regex_part_analyser(sql_statement, \"INSERT_UPDATE\", \n",
    "                                                         r\"(?ims)\\b(?:UPDATE|INTO|TABLE)\\s+([\\[]?[\\w-]+(?:[\\]]?\\.[\\[]?\\w+[\\]]?))(?:,|\\)|;| |$){1}\", df)])\n",
    " \n",
    "        df = pd.concat([df, regex_part_analyser(sql_statement, \"INSERT_UPDATE\", \n",
    "                                                         r\"(?ims)\\b(?:UPDATE|INTO|TABLE)\\s+(?:[\\[]?[\\w-]+(?:[\\]]?\\.[\\[]?\\w+[\\]]?\\.[\\[]?\\w+[\\]]?))\\s*\\w*\\s*,\\s*([\\[]?[\\w-]+(?:[\\]]?\\.[\\[]?\\w+[\\]]?\\.[\\[]?\\w+[\\]]?))(?:,|\\)|;| |$){1}\", df)])   \n",
    "    \n",
    "\n",
    "        df = pd.concat([df, regex_part_analyser(sql_statement, \"SELECT_FROM\", \n",
    "                                                         r\"(?ims)\\b(?:,)\\s+(?:[\\[]?[\\w-]+(?:[\\]]?\\.[\\[]?\\w+[\\]]?))\", df)])\n",
    "                \n",
    "            \n",
    "        df = pd.concat([df, regex_manipulation(sql_statement, \"INSERT_UPDATE\", \n",
    "                                               r\"(?ims)(?:UPDATE|STATISTICS)\\s+([\\[]?[\\w-]+(?:[\\]]?\\.[\\[]?\\w+[\\]]?))\")])  \n",
    "\n",
    "        df = pd.concat([df, regex_manipulation(sql_statement, \"EXEC\",\n",
    "                                               r\"(?ims)\\b(?:EXEC|EXECUTE)\\s+([\\[]?[\\w-]+(?:[\\]]?\\.[\\[]?\\w+[\\]]?))\")])\n",
    "\n",
    "    df = df.drop_duplicates()  \n",
    "    df['SP_SCHEMA'] =rowInput['SP_SCHEMA'] \n",
    "    df['SP_NAME'] =rowInput['SP_NAME'] \n",
    "  # df['SYNTAX'] =rowInput['SYNTAX'] \n",
    "    df['VW_INDEX'] = index\n",
    "    df['SYNTAX_WORDCOUNT'] = len(q.split())\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67c70304-df4c-437a-964e-dcd4a30def38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total count of 1231 SP in the file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1231it [36:46,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COMPLETED : Graph Import File saved to graph_input_sp.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_cat = pd.DataFrame()    \n",
    "\n",
    "print(f\"Total count of {len(df)} SP in the file\")\n",
    "for index, row in tqdm(df.iterrows()):\n",
    "    \n",
    "    #This will put the SQL Syntax into the main regex code analyser to identify table names\n",
    "    if not isNaN(row['SYNTAX']):\n",
    "        df_cat = pd.concat([ df_cat, regex_main_analyser(index, row, row['SYNTAX'])])\n",
    "            \n",
    "print(\"COMPLETED : Graph Import File saved to graph_input_sp.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e0ad06-4765-4460-9750-a406e6c46b76",
   "metadata": {},
   "source": [
    "### Export the results into 3. OUTPUT_GRAPH\n",
    "#### We will add back the remaining SP Name that have not been matched into the Output csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2dd9c36f-2c16-4679-9e5a-2aff6181f1e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TABLE_FULL_NAME</th>\n",
       "      <th>REGEX_TYPE</th>\n",
       "      <th>SP_SCHEMA</th>\n",
       "      <th>SP_NAME</th>\n",
       "      <th>VW_INDEX</th>\n",
       "      <th>SYNTAX_WORDCOUNT</th>\n",
       "      <th>regex_type_value</th>\n",
       "      <th>regex_sum_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[ANALYSE].[ANFIELD_INGESTION_SUMMARY]</td>\n",
       "      <td>INSERT_UPDATE</td>\n",
       "      <td>ANALYSE</td>\n",
       "      <td>ANFIELD_TO_INGESTION_SUMMARY</td>\n",
       "      <td>1</td>\n",
       "      <td>2672</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ANALYSE.ANFIELD_INGESTION_SUMMARY</td>\n",
       "      <td>INSERT_UPDATE</td>\n",
       "      <td>ANALYSE</td>\n",
       "      <td>ANFIELD_TO_INGESTION_SUMMARY</td>\n",
       "      <td>1</td>\n",
       "      <td>2672</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[ANALYSE].[ANFIELD_INGESTION_SUMMARY]</td>\n",
       "      <td>INSERT_UPDATE</td>\n",
       "      <td>ANALYSE</td>\n",
       "      <td>ANFIELD_TO_INGESTION_SUMMARY_ALP</td>\n",
       "      <td>2</td>\n",
       "      <td>2958</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ANALYSE.ANFIELD_INGESTION_SUMMARY</td>\n",
       "      <td>INSERT_UPDATE</td>\n",
       "      <td>ANALYSE</td>\n",
       "      <td>ANFIELD_TO_INGESTION_SUMMARY_ALP</td>\n",
       "      <td>2</td>\n",
       "      <td>2958</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[ANALYSE].[ANFIELD_INGESTION_SUMMARY]</td>\n",
       "      <td>INSERT_UPDATE</td>\n",
       "      <td>ANALYSE</td>\n",
       "      <td>ANFIELD_TO_INGESTION_SUMMARY_IKEA</td>\n",
       "      <td>3</td>\n",
       "      <td>955</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12981</th>\n",
       "      <td>[PUBLISH].[ANFIELD_LOY_MEMBER_ACCOUNT]</td>\n",
       "      <td>SELECT_FROM</td>\n",
       "      <td>PUBLISH_YUU</td>\n",
       "      <td>YUUTB_RFM_TAB_4_SP_MONTHENDUPDATE</td>\n",
       "      <td>1225</td>\n",
       "      <td>1665</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12982</th>\n",
       "      <td>[PUBLISH].[RFM_SEGMENT_MXHK]</td>\n",
       "      <td>SELECT_FROM</td>\n",
       "      <td>PUBLISH_YUU</td>\n",
       "      <td>YUUTB_RFM_TAB_4_SP_MONTHENDUPDATE</td>\n",
       "      <td>1225</td>\n",
       "      <td>1665</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12983</th>\n",
       "      <td>[PUBLISH_YUU].[YUUTB_RFM_TAB_4_DATA]</td>\n",
       "      <td>SELECT_FROM</td>\n",
       "      <td>PUBLISH_YUU</td>\n",
       "      <td>YUUTB_RFM_TAB_4_SP_MONTHENDUPDATE_AGGR</td>\n",
       "      <td>1226</td>\n",
       "      <td>212</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12984</th>\n",
       "      <td>UTIL.DROP_TBL_IF_EXISTS</td>\n",
       "      <td>EXEC</td>\n",
       "      <td>UTIL</td>\n",
       "      <td>CREATE_OR_REPLACE_TBL</td>\n",
       "      <td>1228</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12985</th>\n",
       "      <td>INFORMATION_SCHEMA.TABLES</td>\n",
       "      <td>SELECT_FROM</td>\n",
       "      <td>UTIL</td>\n",
       "      <td>GET_TABLE_SIZE_SQLDW</td>\n",
       "      <td>1230</td>\n",
       "      <td>91</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12986 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              TABLE_FULL_NAME     REGEX_TYPE    SP_SCHEMA  \\\n",
       "0       [ANALYSE].[ANFIELD_INGESTION_SUMMARY]  INSERT_UPDATE      ANALYSE   \n",
       "1           ANALYSE.ANFIELD_INGESTION_SUMMARY  INSERT_UPDATE      ANALYSE   \n",
       "2       [ANALYSE].[ANFIELD_INGESTION_SUMMARY]  INSERT_UPDATE      ANALYSE   \n",
       "3           ANALYSE.ANFIELD_INGESTION_SUMMARY  INSERT_UPDATE      ANALYSE   \n",
       "4       [ANALYSE].[ANFIELD_INGESTION_SUMMARY]  INSERT_UPDATE      ANALYSE   \n",
       "...                                       ...            ...          ...   \n",
       "12981  [PUBLISH].[ANFIELD_LOY_MEMBER_ACCOUNT]    SELECT_FROM  PUBLISH_YUU   \n",
       "12982            [PUBLISH].[RFM_SEGMENT_MXHK]    SELECT_FROM  PUBLISH_YUU   \n",
       "12983    [PUBLISH_YUU].[YUUTB_RFM_TAB_4_DATA]    SELECT_FROM  PUBLISH_YUU   \n",
       "12984                 UTIL.DROP_TBL_IF_EXISTS           EXEC         UTIL   \n",
       "12985               INFORMATION_SCHEMA.TABLES    SELECT_FROM         UTIL   \n",
       "\n",
       "                                      SP_NAME  VW_INDEX  SYNTAX_WORDCOUNT  \\\n",
       "0                ANFIELD_TO_INGESTION_SUMMARY         1              2672   \n",
       "1                ANFIELD_TO_INGESTION_SUMMARY         1              2672   \n",
       "2            ANFIELD_TO_INGESTION_SUMMARY_ALP         2              2958   \n",
       "3            ANFIELD_TO_INGESTION_SUMMARY_ALP         2              2958   \n",
       "4           ANFIELD_TO_INGESTION_SUMMARY_IKEA         3               955   \n",
       "...                                       ...       ...               ...   \n",
       "12981       YUUTB_RFM_TAB_4_SP_MONTHENDUPDATE      1225              1665   \n",
       "12982       YUUTB_RFM_TAB_4_SP_MONTHENDUPDATE      1225              1665   \n",
       "12983  YUUTB_RFM_TAB_4_SP_MONTHENDUPDATE_AGGR      1226               212   \n",
       "12984                   CREATE_OR_REPLACE_TBL      1228                73   \n",
       "12985                    GET_TABLE_SIZE_SQLDW      1230                91   \n",
       "\n",
       "       regex_type_value  regex_sum_value  \n",
       "0                     1                1  \n",
       "1                     1                1  \n",
       "2                     1                1  \n",
       "3                     1                1  \n",
       "4                     1                1  \n",
       "...                 ...              ...  \n",
       "12981                 0                0  \n",
       "12982                 0                0  \n",
       "12983                 0                0  \n",
       "12984                 0                0  \n",
       "12985                 0                0  \n",
       "\n",
       "[12986 rows x 8 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cat2 = df_cat.copy()\n",
    "\n",
    "df_cat2['regex_type_value'] = df_cat2['REGEX_TYPE'].map({'SELECT_FROM': 0, 'EXEC': 0, \n",
    "                                                        'INSERT_UPDATE': 1})\n",
    "\n",
    "df_cat2['regex_sum_value'] = df_cat2.groupby(['TABLE_FULL_NAME', 'VW_INDEX']).regex_type_value.transform(np.sum)\n",
    "\n",
    "df_cat3 = df_cat2.copy()\n",
    "df_cat2 = df_cat2[(df_cat2.regex_sum_value == 1) & (df_cat2.REGEX_TYPE == 'INSERT_UPDATE')]\n",
    "df_cat3 = df_cat3[(df_cat3.regex_sum_value == 0)]\n",
    "\n",
    "df_final = pd.concat([df_cat2, df_cat3], ignore_index=True).drop_duplicates()\n",
    "\n",
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "053e8762-68b9-44bb-95dd-68389fd7ea5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This checks if there are any left out scripts without TABLE name\n",
    "delta_df = pd.merge(df, df_final, how='left', left_on=['SP_SCHEMA','SP_NAME'], right_on = ['SP_SCHEMA','SP_NAME'])\n",
    "delta_df.drop(columns=[\"SYNTAX\"], inplace=True)\n",
    "delta_df['TABLE_FULL_NAME']=delta_df['TABLE_FULL_NAME'].apply(lambda x: final_table_name_cleansing(x))\n",
    "delta_df = delta_df.applymap(lambda s: s.upper() if type(s) == str else s)\n",
    "\n",
    "delta_df.to_csv(graph_ingestion_sp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82ea70b7-16f2-4a6b-9698-99fe161dfbea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SP_SCHEMA</th>\n",
       "      <th>SP_NAME</th>\n",
       "      <th>EXCLUSION</th>\n",
       "      <th>TABLE_FULL_NAME</th>\n",
       "      <th>REGEX_TYPE</th>\n",
       "      <th>VW_INDEX</th>\n",
       "      <th>SYNTAX_WORDCOUNT</th>\n",
       "      <th>regex_type_value</th>\n",
       "      <th>regex_sum_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ANALYSE</td>\n",
       "      <td>ADF_RAISE_EXCEPTION</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ANALYSE</td>\n",
       "      <td>ANFIELD_TO_INGESTION_SUMMARY</td>\n",
       "      <td>False</td>\n",
       "      <td>ANALYSE.ANFIELD_INGESTION_SUMMARY</td>\n",
       "      <td>INSERT_UPDATE</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2672.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ANALYSE</td>\n",
       "      <td>ANFIELD_TO_INGESTION_SUMMARY</td>\n",
       "      <td>False</td>\n",
       "      <td>ANALYSE.ANFIELD_INGESTION_SUMMARY</td>\n",
       "      <td>INSERT_UPDATE</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2672.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ANALYSE</td>\n",
       "      <td>ANFIELD_TO_INGESTION_SUMMARY</td>\n",
       "      <td>False</td>\n",
       "      <td>PREPARE.ANFIELD_ALP_LOCATION_SYNC</td>\n",
       "      <td>SELECT_FROM</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2672.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ANALYSE</td>\n",
       "      <td>ANFIELD_TO_INGESTION_SUMMARY</td>\n",
       "      <td>False</td>\n",
       "      <td>PREPARE.ANFIELD_ALP_PRODUCT_SYNC</td>\n",
       "      <td>SELECT_FROM</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2672.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13099</th>\n",
       "      <td>PUBLISH_YUU</td>\n",
       "      <td>YUUTB_RFM_TAB_4_SP_MONTHENDUPDATE_AGGR</td>\n",
       "      <td>False</td>\n",
       "      <td>PUBLISH_YUU.YUUTB_RFM_TAB_4_DATA</td>\n",
       "      <td>SELECT_FROM</td>\n",
       "      <td>1226.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13100</th>\n",
       "      <td>UTIL</td>\n",
       "      <td>ANFIELD_LOY_PARAMETERS</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13101</th>\n",
       "      <td>UTIL</td>\n",
       "      <td>CREATE_OR_REPLACE_TBL</td>\n",
       "      <td>False</td>\n",
       "      <td>UTIL.DROP_TBL_IF_EXISTS</td>\n",
       "      <td>EXEC</td>\n",
       "      <td>1228.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13102</th>\n",
       "      <td>UTIL</td>\n",
       "      <td>DROP_TBL_IF_EXISTS</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13103</th>\n",
       "      <td>UTIL</td>\n",
       "      <td>GET_TABLE_SIZE_SQLDW</td>\n",
       "      <td>False</td>\n",
       "      <td>INFORMATION_SCHEMA.TABLES</td>\n",
       "      <td>SELECT_FROM</td>\n",
       "      <td>1230.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13104 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         SP_SCHEMA                                 SP_NAME  EXCLUSION  \\\n",
       "0          ANALYSE                     ADF_RAISE_EXCEPTION      False   \n",
       "1          ANALYSE            ANFIELD_TO_INGESTION_SUMMARY      False   \n",
       "2          ANALYSE            ANFIELD_TO_INGESTION_SUMMARY      False   \n",
       "3          ANALYSE            ANFIELD_TO_INGESTION_SUMMARY      False   \n",
       "4          ANALYSE            ANFIELD_TO_INGESTION_SUMMARY      False   \n",
       "...            ...                                     ...        ...   \n",
       "13099  PUBLISH_YUU  YUUTB_RFM_TAB_4_SP_MONTHENDUPDATE_AGGR      False   \n",
       "13100         UTIL                  ANFIELD_LOY_PARAMETERS      False   \n",
       "13101         UTIL                   CREATE_OR_REPLACE_TBL      False   \n",
       "13102         UTIL                      DROP_TBL_IF_EXISTS      False   \n",
       "13103         UTIL                    GET_TABLE_SIZE_SQLDW      False   \n",
       "\n",
       "                         TABLE_FULL_NAME     REGEX_TYPE  VW_INDEX  \\\n",
       "0                                                   NaN       NaN   \n",
       "1      ANALYSE.ANFIELD_INGESTION_SUMMARY  INSERT_UPDATE       1.0   \n",
       "2      ANALYSE.ANFIELD_INGESTION_SUMMARY  INSERT_UPDATE       1.0   \n",
       "3      PREPARE.ANFIELD_ALP_LOCATION_SYNC    SELECT_FROM       1.0   \n",
       "4       PREPARE.ANFIELD_ALP_PRODUCT_SYNC    SELECT_FROM       1.0   \n",
       "...                                  ...            ...       ...   \n",
       "13099   PUBLISH_YUU.YUUTB_RFM_TAB_4_DATA    SELECT_FROM    1226.0   \n",
       "13100                                               NaN       NaN   \n",
       "13101            UTIL.DROP_TBL_IF_EXISTS           EXEC    1228.0   \n",
       "13102                                               NaN       NaN   \n",
       "13103          INFORMATION_SCHEMA.TABLES    SELECT_FROM    1230.0   \n",
       "\n",
       "       SYNTAX_WORDCOUNT  regex_type_value  regex_sum_value  \n",
       "0                   NaN               NaN              NaN  \n",
       "1                2672.0               1.0              1.0  \n",
       "2                2672.0               1.0              1.0  \n",
       "3                2672.0               0.0              0.0  \n",
       "4                2672.0               0.0              0.0  \n",
       "...                 ...               ...              ...  \n",
       "13099             212.0               0.0              0.0  \n",
       "13100               NaN               NaN              NaN  \n",
       "13101              73.0               0.0              0.0  \n",
       "13102               NaN               NaN              NaN  \n",
       "13103              91.0               0.0              0.0  \n",
       "\n",
       "[13104 rows x 9 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Graph",
   "language": "python",
   "name": "graph"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
