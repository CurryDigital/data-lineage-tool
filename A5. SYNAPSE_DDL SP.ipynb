{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2ae6cc6-14c1-43dc-a2c2-f0208e028ea1",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "This will break down the file in the following steps:\n",
    "1. Each \"END GO\" is treated as a unique SQL\n",
    "2. look at each line and remove comments (--)\n",
    "3. Look at comments block then remove (/* */)\n",
    "4. Look for keywords like FROM, JOIN , UPDATE, INTO, CREATE TABLE then grab the next word (Database.Schema.Name or Schema.Name)\n",
    "    (not necessary to find relationships, so all will be just using the RELY_ON relationship.)\n",
    "5. Concatenating into a single dataframe and output to CSV\n",
    "6. Ingest into Graph Database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4fde14e-4939-4103-8040-4d307323e713",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fdce299-6526-4936-9565-532c3cc4dd89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import math\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8fe0ad-7d7b-4c87-8abf-f43e3e887e97",
   "metadata": {},
   "source": [
    "### Import Files\n",
    "#### We will use 1 files from 1.INPUT folder\n",
    "1A. Stored Procedure SQL files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a3f35d1-b5ba-4949-9e8e-dcefe23a8a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_raw_sql_view(sql_input, regex_str):\n",
    "    str_found  = re.findall(regex_str, sql_input)\n",
    "  #  print(\"viewname found\", str_found)\n",
    "    df = pd.DataFrame (str_found, columns = ['SP_SCHEMA', 'SP_NAME'])\n",
    "    df['SYNTAX'] = sql_input\n",
    "    return df\n",
    "\n",
    "\n",
    "def final_table_name_cleansing(text):\n",
    "    if text==text:\n",
    "            input_str = text.replace('FROM', '').replace('JOIN', '').replace(']', '').replace('[', '').replace(' ', '')\n",
    "    else:\n",
    "        input_str = \"\"\n",
    "    return input_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca03cf36-36f2-44b6-aa73-4e808c06e66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open and read the file as a single buffer\n",
    "fd = open('1.INPUT/DATAWAREHOUSE/SPsScript.sql', 'r', encoding=\"utf-16\")\n",
    "sqlFile = fd.read()\n",
    "fd.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04b1a662-6bea-4fc3-9bea-9bdbb780a171",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This convert the raw SQL file into a Dataframe for our later REGEX manipulation\n",
    "\n",
    "df = pd.DataFrame()\n",
    "i= 1\n",
    "\n",
    "for sql_statement in re.split(r'CREATE\\s+PROC', sqlFile):\n",
    "    i = i + 1\n",
    "    concat_sql = \"\"\n",
    "    \n",
    "    for line in sql_statement.split(\"\\n\"):\n",
    "            #Remove anythign on the right of the comment\n",
    "        q = line.split(\"--\")[0]\n",
    "        concat_sql = concat_sql + \" \" + q\n",
    "\n",
    "    concat_sql = concat_sql.replace('\\t', ' ').replace(\"  \", \" \").replace(\"  \", \" \").replace(\"  \", \" \").replace(\"  \", \" \").replace(\"  \", \" \")\n",
    "    concat_sql = re.sub(r\"/\\*[^*]*\\*+(?:[^*/][^*]*\\*+)*/\", \"\", concat_sql)\n",
    "    \n",
    "   # print(concat_sql)\n",
    "    \n",
    "    df = pd.concat([df, read_raw_sql_view(\"CREATE PROC \" + concat_sql, r\"(?ims)\\b(?:CREATE\\s+PROC)\\s+(\\[?\\w+\\]?)\\.(\\[?\\w+\\]?)\")], ignore_index=True )\n",
    "\n",
    "df['SP_SCHEMA']=df['SP_SCHEMA'].apply(lambda x: final_table_name_cleansing(x))\n",
    "df['SP_NAME']=df['SP_NAME'].apply(lambda x: final_table_name_cleansing(x))\n",
    "\n",
    "df.apply(lambda x: x.astype(str).str.upper())\n",
    "df['last_element'] =  df['SP_NAME'].str.split('_').str[-1]\n",
    "\n",
    "\n",
    "# This is where you set logics to exclude certain SP by name\n",
    "exclusion_list = ['TMP', 'TEMP', \n",
    "                  'BCK', 'BKP', 'BACK',\n",
    "                  'TEST', 'RSV']\n",
    "\n",
    "exclusion_list_v2 = [\"_\" + sub for sub in exclusion_list]\n",
    "\n",
    "df['EXCLUSION_v1'] = df['SP_NAME'].apply(lambda x: any([k in x for k in exclusion_list_v2]))\n",
    "df['EXCLUSION_v2'] = df['last_element'].apply(lambda x: any([k in x for k in exclusion_list]))\n",
    "\n",
    "def find_suffix_digits(stringInput):\n",
    "    return bool(re.search(r\"_[\\d]{4,8}$\", stringInput))\n",
    "\n",
    "df['EXCLUSION_digit'] = df['SP_SCHEMA'].apply(lambda x: find_suffix_digits(x))\n",
    "df['EXCLUSION_utils'] = df.SP_SCHEMA.str.contains(\"util\")\n",
    "\n",
    "df['EXCLUSION'] = df.EXCLUSION_v1 | df.EXCLUSION_v2 | df.EXCLUSION_digit | df.EXCLUSION_utils\n",
    "\n",
    "df = df[['SP_SCHEMA', 'SP_NAME', 'SYNTAX', 'EXCLUSION']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5be866-b033-4a3f-b712-c45c037b3524",
   "metadata": {},
   "source": [
    "#### This is what the output dataframe should look like to feed into the Regex Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34b168d9-776d-4584-b20d-a53439fe650e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SP_SCHEMA</th>\n",
       "      <th>SP_NAME</th>\n",
       "      <th>SYNTAX</th>\n",
       "      <th>EXCLUSION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PREPARE</td>\n",
       "      <td>SAMPLE_SP_1</td>\n",
       "      <td>CREATE PROC  [PREPARE].[SAMPLE_SP_1] AS BEGIN ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PREPARE</td>\n",
       "      <td>SAMPLE_SP_2</td>\n",
       "      <td>CREATE PROC  [PREPARE].[SAMPLE_SP_2] AS BEGIN ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  SP_SCHEMA      SP_NAME                                             SYNTAX  \\\n",
       "0   PREPARE  SAMPLE_SP_1  CREATE PROC  [PREPARE].[SAMPLE_SP_1] AS BEGIN ...   \n",
       "1   PREPARE  SAMPLE_SP_2  CREATE PROC  [PREPARE].[SAMPLE_SP_2] AS BEGIN ...   \n",
       "\n",
       "   EXCLUSION  \n",
       "0      False  \n",
       "1      False  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c70ea8-27d7-4d37-9502-fec453f40ca5",
   "metadata": {},
   "source": [
    "### 2. Main ETL Codes\n",
    "#### Now using REGEX to identify the SP-Table relationships\n",
    "#### We will use only the SP Dataframe we got earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82fcb37d-6897-4cf4-a121-ab211c976ca4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "#This function is used to loop complex pattern like \"INSERT INTO FROM SELECT * FROM xxx\"\n",
    "#Since there can be multiple SELECT FROM tables, Will start from the most outer shell, then move inner\n",
    "#If There is a CREATE TABLE/INSERT TABLE statement, then will get from there\n",
    "def regex_part_analyser(sql_input, regex_type, regex_str, df_master):\n",
    "    str_found  = re.findall(regex_str, sql_input)\n",
    "    str_cat=str_found\n",
    "\n",
    "    df = pd.DataFrame (str_cat, columns = ['TABLE_FULL_NAME'])\n",
    "    df['REGEX_TYPE'] = regex_type\n",
    "    return df\n",
    "\n",
    "def regex_manipulation(sql_input, regex_type, regex_str, opt_df=None, opt_col=None):\n",
    "    output = re.findall(regex_str, sql_input)\n",
    "    output = list(dict.fromkeys(output))\n",
    "    \n",
    "    if opt_df is not None:\n",
    "            output = [x for x in output if x not in opt_df[opt_df.REGEX_TYPE==opt_col]['TABLE_FULL_NAME'].tolist()]\n",
    "\n",
    "    df = pd.DataFrame (output, columns = ['TABLE_FULL_NAME'])\n",
    "    df['REGEX_TYPE'] = regex_type\n",
    "    \n",
    "    return df\n",
    "\n",
    "def isNaN(string):\n",
    "    return string != string\n",
    "\n",
    "\n",
    "\n",
    "def regex_main_analyser( index, rowInput, sql_Input):\n",
    "    \n",
    "    # remove the /* */ comments\n",
    "    q = re.sub(r\"/\\*[^*]*\\*+(?:[^*/][^*]*\\*+)*/\", \"\", sql_Input)\n",
    "\n",
    "    #remove the */ and /* comments\n",
    "    q  = re.sub(r\"[^*]*\\*+(?:[^*/][^*]*\\*+)*/\", \"\", q)\n",
    "    q  = re.sub(r\"\\/\\*[^,]*$\", \"\", q)\n",
    "    q  = q.replace('\"','')\n",
    "    q  = q.upper()\n",
    "    df = pd.DataFrame()\n",
    "    #print(q)\n",
    "    \n",
    "    #Splitting the Source Code into multiple SQL statement by ';'\n",
    "    list_sql_statement = q.split(';')\n",
    "    \n",
    "    \n",
    "    for sql_statement in list_sql_statement:\n",
    "\n",
    "        \n",
    "        #1 components TABLE string database.schema.table\n",
    "        df = pd.concat([df, regex_part_analyser(sql_statement, \"SELECT_FROM\", \n",
    "                                                         r\"(?ims)\\b(?:FROM|JOIN)\\s+([\\[]?[\\w-]+(?:[\\]]?\\.[\\[]?\\w+[\\]]?))(?:,|\\)|;| |$){1}\", df)])\n",
    "      \n",
    "        df = pd.concat([df, regex_part_analyser(sql_statement, \"SELECT_FROM\", \n",
    "                                                         r\"(?ims)\\b(?:FROM|JOIN)\\s+(?:[\\[]?[\\w-]+(?:[\\]]?\\.[\\[]?\\w+[\\]]?\\.[\\[]?\\w+[\\]]?))\\s*\\w*\\s*,\\s*([\\[]?[\\w-]+(?:[\\]]?\\.[\\[]?\\w+[\\]]?\\.[\\[]?\\w+[\\]]?))(?:,|\\)|;| |$){1}\", df)])   \n",
    "    \n",
    "    \n",
    "        df = pd.concat([df, regex_part_analyser(sql_statement, \"INSERT_UPDATE\", \n",
    "                                                         r\"(?ims)\\b(?:UPDATE|INTO|TABLE)\\s+([\\[]?[\\w-]+(?:[\\]]?\\.[\\[]?\\w+[\\]]?))(?:,|\\)|;| |$){1}\", df)])\n",
    " \n",
    "        df = pd.concat([df, regex_part_analyser(sql_statement, \"INSERT_UPDATE\", \n",
    "                                                         r\"(?ims)\\b(?:UPDATE|INTO|TABLE)\\s+(?:[\\[]?[\\w-]+(?:[\\]]?\\.[\\[]?\\w+[\\]]?\\.[\\[]?\\w+[\\]]?))\\s*\\w*\\s*,\\s*([\\[]?[\\w-]+(?:[\\]]?\\.[\\[]?\\w+[\\]]?\\.[\\[]?\\w+[\\]]?))(?:,|\\)|;| |$){1}\", df)])   \n",
    "    \n",
    "\n",
    "        df = pd.concat([df, regex_part_analyser(sql_statement, \"SELECT_FROM\", \n",
    "                                                         r\"(?ims)\\b(?:,)\\s+(?:[\\[]?[\\w-]+(?:[\\]]?\\.[\\[]?\\w+[\\]]?))\", df)])\n",
    "                \n",
    "            \n",
    "        df = pd.concat([df, regex_manipulation(sql_statement, \"INSERT_UPDATE\", \n",
    "                                               r\"(?ims)(?:UPDATE|STATISTICS)\\s+([\\[]?[\\w-]+(?:[\\]]?\\.[\\[]?\\w+[\\]]?))\")])  \n",
    "\n",
    "        df = pd.concat([df, regex_manipulation(sql_statement, \"EXEC\",\n",
    "                                               r\"(?ims)\\b(?:EXEC|EXECUTE)\\s+([\\[]?[\\w-]+(?:[\\]]?\\.[\\[]?\\w+[\\]]?))\")])\n",
    "\n",
    "    df = df.drop_duplicates()  \n",
    "    df['SP_SCHEMA'] =rowInput['SP_SCHEMA'] \n",
    "    df['SP_NAME'] =rowInput['SP_NAME'] \n",
    "  # df['SYNTAX'] =rowInput['SYNTAX'] \n",
    "    df['VW_INDEX'] = index\n",
    "    df['SYNTAX_WORDCOUNT'] = len(q.split())\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67c70304-df4c-437a-964e-dcd4a30def38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total count of 2 SP in the file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:00, 27.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COMPLETED : Graph Import File saved to graph_input_sp.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_cat = pd.DataFrame()    \n",
    "\n",
    "print(f\"Total count of {len(df)} SP in the file\")\n",
    "for index, row in tqdm(df.iterrows()):\n",
    "    \n",
    "    #This will put the SQL Syntax into the main regex code analyser to identify table names\n",
    "    if not isNaN(row['SYNTAX']):\n",
    "        df_cat = pd.concat([ df_cat, regex_main_analyser(index, row, row['SYNTAX'])])\n",
    "            \n",
    "print(\"COMPLETED : Graph Import File saved to graph_input_sp.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e0ad06-4765-4460-9750-a406e6c46b76",
   "metadata": {},
   "source": [
    "### Export the results into 3. OUTPUT_GRAPH\n",
    "#### We will add back the remaining SP Name that have not been matched into the Output csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2dd9c36f-2c16-4679-9e5a-2aff6181f1e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TABLE_FULL_NAME</th>\n",
       "      <th>REGEX_TYPE</th>\n",
       "      <th>SP_SCHEMA</th>\n",
       "      <th>SP_NAME</th>\n",
       "      <th>VW_INDEX</th>\n",
       "      <th>SYNTAX_WORDCOUNT</th>\n",
       "      <th>regex_type_value</th>\n",
       "      <th>regex_sum_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[SCHEMA_MALL].[SAMPLE_TB_1]</td>\n",
       "      <td>INSERT_UPDATE</td>\n",
       "      <td>PREPARE</td>\n",
       "      <td>SAMPLE_SP_1</td>\n",
       "      <td>0</td>\n",
       "      <td>198</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[SCHEMA_MALL].[SAMPLE_TB_2]</td>\n",
       "      <td>INSERT_UPDATE</td>\n",
       "      <td>PREPARE</td>\n",
       "      <td>SAMPLE_SP_1</td>\n",
       "      <td>0</td>\n",
       "      <td>198</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[SCHEMA_MALL].[SAMPLE_TB_5]</td>\n",
       "      <td>INSERT_UPDATE</td>\n",
       "      <td>PREPARE</td>\n",
       "      <td>SAMPLE_SP_2</td>\n",
       "      <td>1</td>\n",
       "      <td>92</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[SCHEMA_MALL].[SAMPLE_TB_2]</td>\n",
       "      <td>INSERT_UPDATE</td>\n",
       "      <td>PREPARE</td>\n",
       "      <td>SAMPLE_SP_2</td>\n",
       "      <td>1</td>\n",
       "      <td>92</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[PREPARE].[SAMPLE_TB_3]</td>\n",
       "      <td>SELECT_FROM</td>\n",
       "      <td>PREPARE</td>\n",
       "      <td>SAMPLE_SP_1</td>\n",
       "      <td>0</td>\n",
       "      <td>198</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[PREPARE].[SAMPLE_TB_6]</td>\n",
       "      <td>SELECT_FROM</td>\n",
       "      <td>PREPARE</td>\n",
       "      <td>SAMPLE_SP_2</td>\n",
       "      <td>1</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               TABLE_FULL_NAME     REGEX_TYPE SP_SCHEMA      SP_NAME  \\\n",
       "0  [SCHEMA_MALL].[SAMPLE_TB_1]  INSERT_UPDATE   PREPARE  SAMPLE_SP_1   \n",
       "1  [SCHEMA_MALL].[SAMPLE_TB_2]  INSERT_UPDATE   PREPARE  SAMPLE_SP_1   \n",
       "2  [SCHEMA_MALL].[SAMPLE_TB_5]  INSERT_UPDATE   PREPARE  SAMPLE_SP_2   \n",
       "3  [SCHEMA_MALL].[SAMPLE_TB_2]  INSERT_UPDATE   PREPARE  SAMPLE_SP_2   \n",
       "4      [PREPARE].[SAMPLE_TB_3]    SELECT_FROM   PREPARE  SAMPLE_SP_1   \n",
       "5      [PREPARE].[SAMPLE_TB_6]    SELECT_FROM   PREPARE  SAMPLE_SP_2   \n",
       "\n",
       "   VW_INDEX  SYNTAX_WORDCOUNT  regex_type_value  regex_sum_value  \n",
       "0         0               198                 1                1  \n",
       "1         0               198                 1                1  \n",
       "2         1                92                 1                1  \n",
       "3         1                92                 1                1  \n",
       "4         0               198                 0                0  \n",
       "5         1                92                 0                0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cat2 = df_cat.copy()\n",
    "\n",
    "df_cat2['regex_type_value'] = df_cat2['REGEX_TYPE'].map({'SELECT_FROM': 0, 'EXEC': 0, \n",
    "                                                        'INSERT_UPDATE': 1})\n",
    "\n",
    "df_cat2['regex_sum_value'] = df_cat2.groupby(['TABLE_FULL_NAME', 'VW_INDEX']).regex_type_value.transform(np.sum)\n",
    "\n",
    "df_cat3 = df_cat2.copy()\n",
    "df_cat2 = df_cat2[(df_cat2.regex_sum_value == 1) & (df_cat2.REGEX_TYPE == 'INSERT_UPDATE')]\n",
    "df_cat3 = df_cat3[(df_cat3.regex_sum_value == 0)]\n",
    "\n",
    "df_final = pd.concat([df_cat2, df_cat3], ignore_index=True).drop_duplicates()\n",
    "\n",
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "053e8762-68b9-44bb-95dd-68389fd7ea5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This checks if there are any left out scripts without TABLE name\n",
    "delta_df = pd.merge(df, df_final, how='left', left_on=['SP_SCHEMA','SP_NAME'], right_on = ['SP_SCHEMA','SP_NAME'])\n",
    "delta_df.drop(columns=[\"SYNTAX\"], inplace=True)\n",
    "delta_df['TABLE_FULL_NAME']=delta_df['TABLE_FULL_NAME'].apply(lambda x: final_table_name_cleansing(x))\n",
    "delta_df = delta_df.applymap(lambda s: s.upper() if type(s) == str else s)\n",
    "\n",
    "delta_df.to_csv(f'3.OUTPUT_GRAPH/graph_input_sp.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82ea70b7-16f2-4a6b-9698-99fe161dfbea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SP_SCHEMA</th>\n",
       "      <th>SP_NAME</th>\n",
       "      <th>EXCLUSION</th>\n",
       "      <th>TABLE_FULL_NAME</th>\n",
       "      <th>REGEX_TYPE</th>\n",
       "      <th>VW_INDEX</th>\n",
       "      <th>SYNTAX_WORDCOUNT</th>\n",
       "      <th>regex_type_value</th>\n",
       "      <th>regex_sum_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PREPARE</td>\n",
       "      <td>SAMPLE_SP_1</td>\n",
       "      <td>False</td>\n",
       "      <td>SCHEMA_MALL.SAMPLE_TB_1</td>\n",
       "      <td>INSERT_UPDATE</td>\n",
       "      <td>0</td>\n",
       "      <td>198</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PREPARE</td>\n",
       "      <td>SAMPLE_SP_1</td>\n",
       "      <td>False</td>\n",
       "      <td>SCHEMA_MALL.SAMPLE_TB_2</td>\n",
       "      <td>INSERT_UPDATE</td>\n",
       "      <td>0</td>\n",
       "      <td>198</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PREPARE</td>\n",
       "      <td>SAMPLE_SP_1</td>\n",
       "      <td>False</td>\n",
       "      <td>PREPARE.SAMPLE_TB_3</td>\n",
       "      <td>SELECT_FROM</td>\n",
       "      <td>0</td>\n",
       "      <td>198</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PREPARE</td>\n",
       "      <td>SAMPLE_SP_2</td>\n",
       "      <td>False</td>\n",
       "      <td>SCHEMA_MALL.SAMPLE_TB_5</td>\n",
       "      <td>INSERT_UPDATE</td>\n",
       "      <td>1</td>\n",
       "      <td>92</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PREPARE</td>\n",
       "      <td>SAMPLE_SP_2</td>\n",
       "      <td>False</td>\n",
       "      <td>SCHEMA_MALL.SAMPLE_TB_2</td>\n",
       "      <td>INSERT_UPDATE</td>\n",
       "      <td>1</td>\n",
       "      <td>92</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PREPARE</td>\n",
       "      <td>SAMPLE_SP_2</td>\n",
       "      <td>False</td>\n",
       "      <td>PREPARE.SAMPLE_TB_6</td>\n",
       "      <td>SELECT_FROM</td>\n",
       "      <td>1</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  SP_SCHEMA      SP_NAME  EXCLUSION          TABLE_FULL_NAME     REGEX_TYPE  \\\n",
       "0   PREPARE  SAMPLE_SP_1      False  SCHEMA_MALL.SAMPLE_TB_1  INSERT_UPDATE   \n",
       "1   PREPARE  SAMPLE_SP_1      False  SCHEMA_MALL.SAMPLE_TB_2  INSERT_UPDATE   \n",
       "2   PREPARE  SAMPLE_SP_1      False      PREPARE.SAMPLE_TB_3    SELECT_FROM   \n",
       "3   PREPARE  SAMPLE_SP_2      False  SCHEMA_MALL.SAMPLE_TB_5  INSERT_UPDATE   \n",
       "4   PREPARE  SAMPLE_SP_2      False  SCHEMA_MALL.SAMPLE_TB_2  INSERT_UPDATE   \n",
       "5   PREPARE  SAMPLE_SP_2      False      PREPARE.SAMPLE_TB_6    SELECT_FROM   \n",
       "\n",
       "   VW_INDEX  SYNTAX_WORDCOUNT  regex_type_value  regex_sum_value  \n",
       "0         0               198                 1                1  \n",
       "1         0               198                 1                1  \n",
       "2         0               198                 0                0  \n",
       "3         1                92                 1                1  \n",
       "4         1                92                 1                1  \n",
       "5         1                92                 0                0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Graph",
   "language": "python",
   "name": "graph"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
