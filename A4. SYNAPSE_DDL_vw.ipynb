{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "367b8d56-8e8b-4a35-91eb-30d8ada5b920",
   "metadata": {},
   "source": [
    "## Ingest raw SQL File for Views\n",
    "\n",
    "### Summary\n",
    "\n",
    "This will break down the file in the following steps:\n",
    "1. Each \"; GO\" is treated as a unique SQL\n",
    "2. look at each line and remove comments (--)\n",
    "3. Look at comments block then remove (/* */)\n",
    "4. Look for keywords like FROM, JOIN , then grab the next word (Schema.Name)\n",
    "5. Concatenating into a single dataframe and output to CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d242b0-c078-4fcc-81e4-7cec29ed7b5c",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5fdce299-6526-4936-9565-532c3cc4dd89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import math\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e009252-ec78-493b-8de0-ebe82fa294b6",
   "metadata": {},
   "source": [
    "### Import Files\n",
    "#### We will use 1 files from 1.INPUT folder\n",
    "1A. VIEW SQL files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38bcf997-9159-49ac-972f-7b7f88dd8bb6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_raw_sql_view(sql_input, regex_str):\n",
    "    str_found  = re.findall(regex_str, sql_input)\n",
    "  #  print(\"viewname found\", str_found)\n",
    "    df = pd.DataFrame (str_found, columns = ['VW_SCHEMA', 'VW_NAME'])\n",
    "    df['SYNTAX'] = sql_input\n",
    "    return df\n",
    "\n",
    "def final_table_name_cleansing(text):\n",
    "    if text==text:\n",
    "          #  input_str=re.findall(r'(\\[?\\w+\\]?\\.\\[?\\w+\\]?)', text)\n",
    "            input_str = text.replace('FROM', '').replace('JOIN', '').replace(']', '').replace('[', '').replace(' ', '')\n",
    "    else:\n",
    "        input_str = \"\"\n",
    "    return input_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "45f45acb-ec13-406d-94ab-ff21bc5d7786",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Open and read the file as a single buffer\n",
    "fd = open('1.INPUT/DATAWAREHOUSE/ViewScript.sql', 'r', encoding=\"utf-16\")\n",
    "sqlFile = fd.read()\n",
    "fd.close()\n",
    "\n",
    "#This convert the raw SQL file into a Dataframe for our later REGEX manipulation\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "for sql_statement in re.split(r'(?:;(\\s+|\\n))(GO)', sqlFile):\n",
    "   # print(\"split\")\n",
    "    concat_sql = \"\"\n",
    "    \n",
    "    for line in sql_statement.split(\"\\n\"):\n",
    "            #Remove anythign on the right of the comment\n",
    "        q = line.split(\"--\")[0]\n",
    "        concat_sql = concat_sql + \" \" + q\n",
    "\n",
    "    concat_sql = concat_sql.replace('\\t', ' ').replace(\"  \", \" \").replace(\"  \", \" \").replace(\"  \", \" \").replace(\"  \", \" \").replace(\"  \", \" \")\n",
    "    concat_sql = re.sub(r\"/\\*[^*]*\\*+(?:[^*/][^*]*\\*+)*/\", \"\", concat_sql)\n",
    "    \n",
    "   # print(concat_sql)\n",
    "    \n",
    "    df = pd.concat([df, read_raw_sql_view(concat_sql, r\"(?ims)\\b(?:CREATE\\s+VIEW)\\s+(\\[?\\w+\\]?)\\.(\\[?\\w+\\]?)\")], ignore_index=True )\n",
    "\n",
    "df['VW_SCHEMA']=df['VW_SCHEMA'].apply(lambda x: final_table_name_cleansing(x))\n",
    "df['VW_NAME']=df['VW_NAME'].apply(lambda x: final_table_name_cleansing(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8d6dee48-464a-41d2-acfd-568048c9e6bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VW_SCHEMA</th>\n",
       "      <th>VW_NAME</th>\n",
       "      <th>SYNTAX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>prepare</td>\n",
       "      <td>SAMPLE_TB_6_VW</td>\n",
       "      <td>SET ANSI_NULLS ON GO SET QUOTED_IDENTIFIER O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>schema_mall</td>\n",
       "      <td>SAMPLE_TB_1_temp_view</td>\n",
       "      <td>SET ANSI_NULLS ON GO SET QUOTED_IDENTIFIER O...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     VW_SCHEMA                VW_NAME  \\\n",
       "0      prepare         SAMPLE_TB_6_VW   \n",
       "1  schema_mall  SAMPLE_TB_1_temp_view   \n",
       "\n",
       "                                              SYNTAX  \n",
       "0    SET ANSI_NULLS ON GO SET QUOTED_IDENTIFIER O...  \n",
       "1    SET ANSI_NULLS ON GO SET QUOTED_IDENTIFIER O...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e336d56-0171-4e6f-8abf-70f1ff2f37b0",
   "metadata": {},
   "source": [
    "### 2. Now using REGEX to identify the View-Table relationships\n",
    "#### We will use the View Dataframe we got earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "20ae0982-7b0c-4261-aafc-6e70947b7713",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "#This function is used to loop complex pattern like \"INSERT INTO FROM SELECT * FROM xxx\"\n",
    "#Since there can be multiple SELECT FROM tables, Will start from the most outer shell, then move inner\n",
    "#If There is a CREATE TABLE/INSERT TABLE statement, then will get from there\n",
    "def regex_part_analyser(sql_input, regex_type, regex_str, df_master):\n",
    "    str_found  = re.findall(regex_str, sql_input)\n",
    "    str_cat=[]\n",
    "    \n",
    "    while str_found:\n",
    "        sql_input = sql_input.replace(str_found[0], '')\n",
    "        str_cat = str_cat + str_found\n",
    "        str_found  = re.findall(regex_str, sql_input)\n",
    "\n",
    "    df = pd.DataFrame (str_cat, columns = ['TABLE_FULL_NAME'])\n",
    "    df['REGEX_TYPE'] = regex_type\n",
    "    return df\n",
    "        \n",
    "def isNaN(string):\n",
    "    return string != string\n",
    "\n",
    "def regex_main_analyser( index, rowInput, sql_Input):\n",
    "    \n",
    "    # remove the /* */ comments\n",
    "    q = re.sub(r\"/\\*[^*]*\\*+(?:[^*/][^*]*\\*+)*/\", \"\", sql_Input)\n",
    "\n",
    "    #remove the */ and /* comments\n",
    "    q  = re.sub(r\"[^*]*\\*+(?:[^*/][^*]*\\*+)*/\", \"\", q)\n",
    "    q  = re.sub(r\"\\/\\*[^,]*$\", \"\", q)\n",
    "    q  = q.replace('\"','')\n",
    "    q  = q.upper()\n",
    "    df = pd.DataFrame()\n",
    "    #print(q)\n",
    "    \n",
    "    #Splitting the Source Code into multiple SQL statement by ';'\n",
    "    list_sql_statement = q.split(';')\n",
    "    \n",
    "    \n",
    "    for sql_statement in list_sql_statement:\n",
    "        #print(sql_statement)\n",
    "        #To be fixed\n",
    "    #    df = pd.concat([df, regex_part_analyser(sql_statement, \"SELECT_FROM\", \n",
    "    #                                                     r\"(?ims)\\b(?:SELECT)\\s.*\\b((?:FROM|JOIN|UPDATE)\\s+\\[?\\w+\\]?\\.\\[?\\w+\\]?)\", df)])\n",
    "        \n",
    "         #2 components TABLE string database.schema.table\n",
    "        df = pd.concat([df, regex_part_analyser(sql_statement, \"SELECT_FROM\", \n",
    "                                                         r\"(?ims)\\b(?:FROM|JOIN)\\s+([\\[]?[\\w-]+(?:[\\]]?\\.[\\[]?\\w+[\\]]?))(?:,|\\)|;| |$){1}\", df)])\n",
    "\n",
    "        #if the table name is like this [SCHEMA].[TABLE]IT then the square bracket must exists\n",
    "        df = pd.concat([df, regex_part_analyser(sql_statement, \"SELECT_FROM\", \n",
    "                                                         r\"(?ims)\\b(?:FROM|JOIN)\\s+([\\[]?[\\w-]+(?:[\\]]?\\.[\\[]?\\w+[\\]]))\", df)])        \n",
    "        \n",
    "        #This matches for the JOIN then comma\n",
    "        df = pd.concat([df, regex_part_analyser(sql_statement, \"SELECT_FROM\", \n",
    "                                                         r\"(?ims)\\b(?:FROM|JOIN)\\s+(?:[\\[]?[\\w-]+(?:[\\]]?\\.[\\[]?\\w+[\\]]?))\\s+\\w*\\s*,\\s*([\\[]?[\\w-]+(?:[\\]]?\\.[\\[]?\\w+[\\]]?))\", df)])\n",
    "      \n",
    "        \n",
    "        #3 components TABLE string database.schema.table\n",
    "        df = pd.concat([df, regex_part_analyser(sql_statement, \"SELECT_FROM\", \n",
    "                                                         r\"(?ims)\\b(?:FROM|JOIN)\\s+([\\[]?[\\w-]+(?:[\\]]?\\.[\\[]?\\w+[\\]]?\\.[\\[]?\\w+[\\]]?))(?:,|\\)|;| |$){1}\", df)])\n",
    "\n",
    "        \n",
    "        #if the table name is like this [DATABASE].[SCHEMA].[TABLE]IT then the square bracket must exists\n",
    "        df = pd.concat([df, regex_part_analyser(sql_statement, \"SELECT_FROM\", \n",
    "                                                         r\"(?ims)\\b(?:FROM|JOIN)\\s+([\\[]?[\\w-]+(?:[\\]]?\\.[\\[]?\\w+[\\]]?\\.[\\[]?\\w+[\\]]))\", df)])        \n",
    "\n",
    "        \n",
    "                #This matches for the JOIN then comma\n",
    "        df = pd.concat([df, regex_part_analyser(sql_statement, \"SELECT_FROM\", \n",
    "                                                         r\"(?ims)\\b(?:FROM|JOIN)\\s+(?:[\\[]?[\\w-]+(?:[\\]]?\\.[\\[]?\\w+[\\]]?\\.[\\[]?\\w+[\\]]?))\\s+\\w*\\s*,\\s*([\\[]?[\\w-]+(?:[\\]]?\\.[\\[]?\\w+[\\]]?\\.[\\[]?\\w+[\\]]?))\", df)])\n",
    "        \n",
    "        \n",
    "    df = df.drop_duplicates()  \n",
    "    df['VW_SCHEMA'] =rowInput['VW_SCHEMA'] \n",
    "    df['VW_NAME'] =rowInput['VW_NAME'] \n",
    "    df['SYNTAX'] =rowInput['SYNTAX'] \n",
    "    df['VW_INDEX'] = index\n",
    "    df['SYNTAX_WORDCOUNT'] = len(q.split())\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5c9820-2262-47b7-8192-1b2fd91f0b06",
   "metadata": {},
   "source": [
    "### Export the results into 3. OUTPUT_GRAPH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "759f19f0-4db4-4057-8d4c-02e0452b37fd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total count of 2 VW in the file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:00, 129.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COMPLETED : Graph Import File saved to output_vw.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Each Row in the Dataframe are looped iteratively against the REGEX logics\n",
    "\n",
    "df_cat = pd.DataFrame()    \n",
    "\n",
    "print(f\"Total count of {len(df)} VW in the file\")\n",
    "for index, row in tqdm(df.iterrows()):\n",
    "    \n",
    "    #This will put the SQL Syntax into the main regex code analyser to identify table names\n",
    "    if not isNaN(row['SYNTAX']):\n",
    "        df_cat = pd.concat([ df_cat, regex_main_analyser(index, row, row['SYNTAX'])])\n",
    "    \n",
    "if not df_cat.empty:\n",
    "    #This will clean up the FULL TABLE NAME, and split them into Database, Schema, Name\n",
    "    df_cat['test']=df_cat['TABLE_FULL_NAME'].apply(lambda x: final_table_name_cleansing(x))\n",
    "    df_cat[[\"PART1\", \"PART2\", \"PART3\"]] = df_cat[\"test\"].str.split(pat=\".\",  expand=True)\n",
    "                                          \n",
    "    df_cat['TABLE_DATABASE'] = np.select([~df_cat.PART3.isnull()], [df_cat.PART1], default=None )\n",
    "    df_cat['TABLE_SCHEMA'] = np.select([~df_cat.PART3.isnull()], [df_cat.PART2], default=df_cat.PART1 )\n",
    "    df_cat['TABLE_NAME'] = np.select([~df_cat.PART3.isnull()], [df_cat.PART3], default=df_cat.PART2 )\n",
    "\n",
    "    \n",
    "    df_cat.drop(columns=[\"PART1\", \"PART2\", \"PART3\", 'test'], inplace=True)\n",
    "    \n",
    "df_cat.to_csv(f'3.OUTPUT_GRAPH/graph_input_vw.csv')\n",
    "            \n",
    "print(\"COMPLETED : Graph Import File saved to output_vw.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "79d6498b-b842-4e1f-9b9a-3e73d6b17a37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TABLE_FULL_NAME</th>\n",
       "      <th>REGEX_TYPE</th>\n",
       "      <th>VW_SCHEMA</th>\n",
       "      <th>VW_NAME</th>\n",
       "      <th>SYNTAX</th>\n",
       "      <th>VW_INDEX</th>\n",
       "      <th>SYNTAX_WORDCOUNT</th>\n",
       "      <th>TABLE_DATABASE</th>\n",
       "      <th>TABLE_SCHEMA</th>\n",
       "      <th>TABLE_NAME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PREPARE.SAMPLE_TB_6</td>\n",
       "      <td>SELECT_FROM</td>\n",
       "      <td>prepare</td>\n",
       "      <td>SAMPLE_TB_6_VW</td>\n",
       "      <td>SET ANSI_NULLS ON GO SET QUOTED_IDENTIFIER O...</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>None</td>\n",
       "      <td>PREPARE</td>\n",
       "      <td>SAMPLE_TB_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DATABASE1.SCHEMA_MALL.SAMPLE_TB_1</td>\n",
       "      <td>SELECT_FROM</td>\n",
       "      <td>schema_mall</td>\n",
       "      <td>SAMPLE_TB_1_temp_view</td>\n",
       "      <td>SET ANSI_NULLS ON GO SET QUOTED_IDENTIFIER O...</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>DATABASE1</td>\n",
       "      <td>SCHEMA_MALL</td>\n",
       "      <td>SAMPLE_TB_1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     TABLE_FULL_NAME   REGEX_TYPE    VW_SCHEMA  \\\n",
       "0                PREPARE.SAMPLE_TB_6  SELECT_FROM      prepare   \n",
       "0  DATABASE1.SCHEMA_MALL.SAMPLE_TB_1  SELECT_FROM  schema_mall   \n",
       "\n",
       "                 VW_NAME                                             SYNTAX  \\\n",
       "0         SAMPLE_TB_6_VW    SET ANSI_NULLS ON GO SET QUOTED_IDENTIFIER O...   \n",
       "0  SAMPLE_TB_1_temp_view    SET ANSI_NULLS ON GO SET QUOTED_IDENTIFIER O...   \n",
       "\n",
       "   VW_INDEX  SYNTAX_WORDCOUNT TABLE_DATABASE TABLE_SCHEMA   TABLE_NAME  \n",
       "0         0                42           None      PREPARE  SAMPLE_TB_6  \n",
       "0         1                38      DATABASE1  SCHEMA_MALL  SAMPLE_TB_1  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cat"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Graph",
   "language": "python",
   "name": "graph"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
