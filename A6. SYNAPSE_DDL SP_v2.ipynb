{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2ae6cc6-14c1-43dc-a2c2-f0208e028ea1",
   "metadata": {},
   "source": [
    "### Summary\n",
    "#### This will break down the file in the following steps:\n",
    "1. loop through the table name file and see if anythings matched in the SQL script\n",
    "2. This won't look at the syntax patterns, just basically seeing if the TABLE name exists"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2987f729-c90d-41f7-b6a2-f12d06748312",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fdce299-6526-4936-9565-532c3cc4dd89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "import shutil\n",
    "\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "282f90ae-06dc-4fbd-b785-1f5727891217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_script_view =  1.INPUT/DATAWAREHOUSE/ViewScript.sql\n",
      "input_script_sp =  1.INPUT/DATAWAREHOUSE/SPsScript.sql\n",
      "input_script_table =  1.INPUT/DATAWAREHOUSE/tableScript.sql\n",
      "graph_ingestion_view =  3.OUTPUT_GRAPH/graph_input_vw.csv\n",
      "graph_ingestion_sp =  3.OUTPUT_GRAPH/graph_input_sp.csv\n",
      "graph_ingestion_sp2 =  3.OUTPUT_GRAPH/graph_input_sp2.csv\n",
      "graph_ingestion_table =  3.OUTPUT_GRAPH/graph_input_table.csv\n"
     ]
    }
   ],
   "source": [
    "%run \"0_Configuration.ipynb\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ed757f-936b-4bb1-b218-eb97ff787de7",
   "metadata": {},
   "source": [
    "### 1. Import Files\n",
    "#### We will use 2 files from 1.INPUT folder\n",
    "1A. Stored Procedure SQL files\n",
    "\n",
    "1B. Excel Table Name files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f66dd5d-51fa-41d9-9c69-a74889798adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_raw_sql_view(sql_input, regex_str):\n",
    "    str_found  = re.findall(regex_str, sql_input)\n",
    "  #  print(\"viewname found\", str_found)\n",
    "    df = pd.DataFrame (str_found, columns = ['SP_SCHEMA', 'SP_NAME'])\n",
    "    df['SYNTAX'] = sql_input\n",
    "    return df\n",
    "\n",
    "def read_raw_sql_table(sql_input, regex_str):\n",
    "    str_found  = re.findall(regex_str, sql_input)\n",
    "  #  print(\"viewname found\", str_found)\n",
    "    df = pd.DataFrame (str_found, columns = ['TABLE_SCHEMA', 'TABLE_NAME'])\n",
    "    df['SYNTAX'] = sql_input\n",
    "    return df\n",
    "\n",
    "\n",
    "def sql_syntax_cleansing(text):\n",
    "    if text==text:\n",
    "        # remove the /* */ comments\n",
    "        q = re.sub(r\"/\\*[^*]*\\*+(?:[^*/][^*]*\\*+)*/\", \"\", text)\n",
    "\n",
    "        #remove the */ and /* comments\n",
    "        #q  = re.sub(r\"[^*]*\\*+(?:[^*/][^*]*\\*+)*/\", \"\", q)\n",
    "        q  = re.sub(r\"\\/\\*[^,]*$\", \"\", q)\n",
    "        q  = q.replace('\"','')\n",
    "        q  = q.replace('[','').replace(']','')\n",
    "        input_str  = q.upper()\n",
    "    else:\n",
    "        input_str = \"\"\n",
    "    return input_str\n",
    "\n",
    "def final_table_name_cleansing(text):\n",
    "    if text==text:\n",
    "          #  input_str=re.findall(r'(\\[?\\w+\\]?\\.\\[?\\w+\\]?)', text)\n",
    "            input_str = text.replace('FROM', '').replace('JOIN', '').replace(']', '').replace('[', '').replace(' ', '').upper()\n",
    "    else:\n",
    "        input_str = \"\"\n",
    "    return input_str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dfd11d8-aea4-45e4-b327-d4a93f24fdbe",
   "metadata": {},
   "source": [
    "#### 1A. Store Procedure SQL files into a Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca03cf36-36f2-44b6-aa73-4e808c06e66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open and read the SP SQL file as a single buffer\n",
    "fd = open(input_script_sp, 'r', encoding=\"utf-16\")\n",
    "sqlFile = fd.read()\n",
    "fd.close()\n",
    "\n",
    "#Then we clean the Stored Procedure Dataframe\n",
    "df = pd.DataFrame()\n",
    "i= 1\n",
    "\n",
    "for sql_statement in re.split(r'CREATE\\s+PROC', sqlFile):\n",
    "    i = i + 1\n",
    "    concat_sql = \"\"\n",
    "    sql_statement = sql_statement.upper()\n",
    "    \n",
    "    for line in sql_statement.split(\"\\n\"):\n",
    "            #Remove anythign on the right of the comment\n",
    "        q = line.split(\"--\")[0]\n",
    "        concat_sql = concat_sql + \" \" + q\n",
    "\n",
    "    concat_sql = concat_sql.replace('\\t', ' ').replace(\"  \", \" \").replace(\"  \", \" \").replace(\"  \", \" \").replace(\"  \", \" \").replace(\"  \", \" \")\n",
    "    concat_sql = re.sub(r\"/\\*[^*]*\\*+(?:[^*/][^*]*\\*+)*/\", \"\", concat_sql)\n",
    "    \n",
    "   # print(concat_sql)\n",
    "    \n",
    "    df = pd.concat([df, read_raw_sql_view(\"CREATE PROC \" + concat_sql, r\"(?ims)\\b(?:CREATE\\s+PROC)\\s+(\\[?\\w+\\]?)\\.(\\[?\\w+\\]?)\")], ignore_index=True )\n",
    "\n",
    "df['SP_SCHEMA']=df['SP_SCHEMA'].apply(lambda x: final_table_name_cleansing(x))\n",
    "df['SP_NAME']=df['SP_NAME'].apply(lambda x: final_table_name_cleansing(x))\n",
    "df['SYNTAX']=df['SYNTAX'].apply(lambda x: sql_syntax_cleansing(x))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2af6b47-c65d-4a69-a5ba-387b24b70db6",
   "metadata": {},
   "source": [
    "#### 1B. Store Procedure SQL file into a Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "135b4be6-a121-4926-aa9d-65ac9d876c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open and read the Table name (Table List as csv)\n",
    "#table_name_df = pd.read_csv('1.INPUT/DATAWAREHOUSE/tableList.csv', header=0)\n",
    "#table_name_df= table_name_df.rename(columns={\"database\": \"TABLE_DATABASE\",\n",
    "#                       \"schema\": \"TABLE_SCHEMA\",\n",
    "#                       \"name\": \"TABLE_NAME\"\n",
    "#                      })\n",
    "\n",
    "#table_name_df = table_name_df[[\"TABLE_DATABASE\", 'TABLE_SCHEMA', 'TABLE_NAME']]\n",
    "\n",
    "#table_name_df = table_name_df.drop_duplicates(ignore_index=True)\n",
    "\n",
    "\n",
    "#First we clean the Table Name Dataframe\n",
    "#table_name_df['TABLE_SCHEMA']=table_name_df['TABLE_SCHEMA'].apply(lambda x: sql_syntax_cleansing(x))\n",
    "#table_name_df['TABLE_NAME']=table_name_df['TABLE_NAME'].apply(lambda x: sql_syntax_cleansing(x))\n",
    "\n",
    "\n",
    "# Open and read the Table name (Table List as SQL DDL file)\n",
    "# Open and read the file as a single buffer\n",
    "fd = open(input_script_table, 'r', encoding=\"utf-8\")\n",
    "sqlFile = fd.read()\n",
    "fd.close()\n",
    "\n",
    "#This convert the raw SQL file into a Dataframe for our later REGEX manipulation\n",
    "\n",
    "table_name_df = pd.DataFrame()\n",
    "i= 1\n",
    "\n",
    "for sql_statement in re.split(r'CREATE\\s+TABLE', sqlFile):\n",
    "    i = i + 1\n",
    "    concat_sql = \"\"\n",
    "    sql_statement = sql_statement.upper()\n",
    "    \n",
    "    for line in sql_statement.split(\"\\n\"):\n",
    "            #Remove anythign on the right of the comment\n",
    "        q = line.split(\"--\")[0]\n",
    "        concat_sql = concat_sql + \" \" + q\n",
    "\n",
    "    concat_sql = concat_sql.replace('\\t', ' ').replace(\"  \", \" \").replace(\"  \", \" \").replace(\"  \", \" \").replace(\"  \", \" \").replace(\"  \", \" \")\n",
    "    concat_sql = re.sub(r\"/\\*[^*]*\\*+(?:[^*/][^*]*\\*+)*/\", \"\", concat_sql)\n",
    "    \n",
    "    table_name_df = pd.concat([table_name_df, read_raw_sql_table(\"CREATE TABLE \" + concat_sql, r\"(?ims)\\b(?:CREATE\\s+TABLE)\\s+(\\[?\\w+\\]?)\\.(\\[?\\w+\\]?)\")], ignore_index=True )\n",
    "\n",
    "table_name_df['TABLE_SCHEMA']=table_name_df['TABLE_SCHEMA'].apply(lambda x: final_table_name_cleansing(x))\n",
    "table_name_df['TABLE_NAME']=table_name_df['TABLE_NAME'].apply(lambda x: final_table_name_cleansing(x))\n",
    "\n",
    "table_name_df.apply(lambda x: x.astype(str).str.upper())\n",
    "table_name_df['last_element'] =  table_name_df['TABLE_NAME'].str.split('_').str[-1]\n",
    "\n",
    "\n",
    "# This is where you set logics to exclude certain SP by name\n",
    "exclusion_list = ['TMP', 'TEMP', \n",
    "                  'BCK', 'BKP', 'BACK',\n",
    "                  'TEST', 'RSV']\n",
    "\n",
    "exclusion_list_v2 = [\"_\" + sub for sub in exclusion_list]\n",
    "\n",
    "table_name_df['EXCLUSION_v1'] = table_name_df['TABLE_NAME'].apply(lambda x: any([k in x for k in exclusion_list_v2]))\n",
    "table_name_df['EXCLUSION_v2'] = table_name_df['last_element'].apply(lambda x: any([k in x for k in exclusion_list]))\n",
    "\n",
    "def find_suffix_digits(stringInput):\n",
    "    return bool(re.search(r\"_[\\d]{4,8}$\", stringInput))\n",
    "\n",
    "table_name_df['EXCLUSION_digit'] = table_name_df['TABLE_NAME'].apply(lambda x: find_suffix_digits(x))\n",
    "table_name_df['EXCLUSION_utils'] = table_name_df.TABLE_SCHEMA.str.contains(\"util\")\n",
    "\n",
    "table_name_df['EXCLUSION'] = table_name_df.EXCLUSION_v1 | table_name_df.EXCLUSION_v2 | table_name_df.EXCLUSION_digit | table_name_df.EXCLUSION_utils\n",
    "\n",
    "table_name_df = table_name_df[['TABLE_SCHEMA', 'TABLE_NAME', 'EXCLUSION']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65ab81f-ccac-49d4-8cfb-db36494ce1fc",
   "metadata": {},
   "source": [
    "#### What the 2 Dataframe should look like :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ccfb9521-5c7f-4816-9c05-e9d4265ca5f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SP_SCHEMA</th>\n",
       "      <th>SP_NAME</th>\n",
       "      <th>SYNTAX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ANALYSE</td>\n",
       "      <td>ADF_RAISE_EXCEPTION</td>\n",
       "      <td>CREATE PROC  ANALYSE.ADF_RAISE_EXCEPTION @ERRO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ANALYSE</td>\n",
       "      <td>ANFIELD_TO_INGESTION_SUMMARY</td>\n",
       "      <td>CREATE PROC  ANALYSE.ANFIELD_TO_INGESTION_SUMM...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ANALYSE</td>\n",
       "      <td>ANFIELD_TO_INGESTION_SUMMARY_ALP</td>\n",
       "      <td>CREATE PROC  ANALYSE.ANFIELD_TO_INGESTION_SUMM...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ANALYSE</td>\n",
       "      <td>ANFIELD_TO_INGESTION_SUMMARY_IKEA</td>\n",
       "      <td>CREATE PROC  ANALYSE.ANFIELD_TO_INGESTION_SUMM...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ANALYSE</td>\n",
       "      <td>ANFIELD_TO_INGESTION_SUMMARY_MA</td>\n",
       "      <td>CREATE PROC  ANALYSE.ANFIELD_TO_INGESTION_SUMM...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1226</th>\n",
       "      <td>PUBLISH_YUU</td>\n",
       "      <td>YUUTB_RFM_TAB_4_SP_MONTHENDUPDATE_AGGR</td>\n",
       "      <td>CREATE PROC  PUBLISH_YUU.YUUTB_RFM_TAB_4_SP_MO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1227</th>\n",
       "      <td>UTIL</td>\n",
       "      <td>ANFIELD_LOY_PARAMETERS</td>\n",
       "      <td>CREATE PROC  UTIL.ANFIELD_LOY_PARAMETERS @PREV...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1228</th>\n",
       "      <td>UTIL</td>\n",
       "      <td>CREATE_OR_REPLACE_TBL</td>\n",
       "      <td>CREATE PROC  UTIL.CREATE_OR_REPLACE_TBL @FROM_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1229</th>\n",
       "      <td>UTIL</td>\n",
       "      <td>DROP_TBL_IF_EXISTS</td>\n",
       "      <td>CREATE PROC  UTIL.DROP_TBL_IF_EXISTS @TBL NVAR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1230</th>\n",
       "      <td>UTIL</td>\n",
       "      <td>GET_TABLE_SIZE_SQLDW</td>\n",
       "      <td>CREATE PROC  UTIL.GET_TABLE_SIZE_SQLDW @SRCSCH...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1231 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        SP_SCHEMA                                 SP_NAME  \\\n",
       "0         ANALYSE                     ADF_RAISE_EXCEPTION   \n",
       "1         ANALYSE            ANFIELD_TO_INGESTION_SUMMARY   \n",
       "2         ANALYSE        ANFIELD_TO_INGESTION_SUMMARY_ALP   \n",
       "3         ANALYSE       ANFIELD_TO_INGESTION_SUMMARY_IKEA   \n",
       "4         ANALYSE         ANFIELD_TO_INGESTION_SUMMARY_MA   \n",
       "...           ...                                     ...   \n",
       "1226  PUBLISH_YUU  YUUTB_RFM_TAB_4_SP_MONTHENDUPDATE_AGGR   \n",
       "1227         UTIL                  ANFIELD_LOY_PARAMETERS   \n",
       "1228         UTIL                   CREATE_OR_REPLACE_TBL   \n",
       "1229         UTIL                      DROP_TBL_IF_EXISTS   \n",
       "1230         UTIL                    GET_TABLE_SIZE_SQLDW   \n",
       "\n",
       "                                                 SYNTAX  \n",
       "0     CREATE PROC  ANALYSE.ADF_RAISE_EXCEPTION @ERRO...  \n",
       "1     CREATE PROC  ANALYSE.ANFIELD_TO_INGESTION_SUMM...  \n",
       "2     CREATE PROC  ANALYSE.ANFIELD_TO_INGESTION_SUMM...  \n",
       "3     CREATE PROC  ANALYSE.ANFIELD_TO_INGESTION_SUMM...  \n",
       "4     CREATE PROC  ANALYSE.ANFIELD_TO_INGESTION_SUMM...  \n",
       "...                                                 ...  \n",
       "1226  CREATE PROC  PUBLISH_YUU.YUUTB_RFM_TAB_4_SP_MO...  \n",
       "1227  CREATE PROC  UTIL.ANFIELD_LOY_PARAMETERS @PREV...  \n",
       "1228  CREATE PROC  UTIL.CREATE_OR_REPLACE_TBL @FROM_...  \n",
       "1229  CREATE PROC  UTIL.DROP_TBL_IF_EXISTS @TBL NVAR...  \n",
       "1230  CREATE PROC  UTIL.GET_TABLE_SIZE_SQLDW @SRCSCH...  \n",
       "\n",
       "[1231 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "249de4b0-b0b8-42de-ac93-d71e03a1fe6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TABLE_SCHEMA</th>\n",
       "      <th>TABLE_NAME</th>\n",
       "      <th>EXCLUSION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ANALYSE</td>\n",
       "      <td>HKMN_MD_ITEM</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ANALYSE</td>\n",
       "      <td>HKMN_MD_MMDS_PROMOTION</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ANALYSE</td>\n",
       "      <td>HKMN_MD_TIME</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ANALYSE</td>\n",
       "      <td>HKMN_MD_STORE</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ANALYSE</td>\n",
       "      <td>HKMN_TX_SALES_DETAIL</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3315</th>\n",
       "      <td>PUBLISH_YUU</td>\n",
       "      <td>YUUTB_RFM_TAB_4_DATA</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3316</th>\n",
       "      <td>PUBLISH_YUU</td>\n",
       "      <td>YUUTB_RFM_TAB_4_DATA_AGGR</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3317</th>\n",
       "      <td>PUBLISH_YUU</td>\n",
       "      <td>YUUTB_RFM_TAB_4_DATA_AGGR_BAK_20220629</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3318</th>\n",
       "      <td>PUBLISH_YUU</td>\n",
       "      <td>YUUTB_RFM_TAB_4_DATA2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3319</th>\n",
       "      <td>UTIL</td>\n",
       "      <td>ANFIELD_LOY_COMMON_PARAMETERS</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3320 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     TABLE_SCHEMA                              TABLE_NAME  EXCLUSION\n",
       "0         ANALYSE                            HKMN_MD_ITEM      False\n",
       "1         ANALYSE                  HKMN_MD_MMDS_PROMOTION      False\n",
       "2         ANALYSE                            HKMN_MD_TIME      False\n",
       "3         ANALYSE                           HKMN_MD_STORE      False\n",
       "4         ANALYSE                    HKMN_TX_SALES_DETAIL      False\n",
       "...           ...                                     ...        ...\n",
       "3315  PUBLISH_YUU                    YUUTB_RFM_TAB_4_DATA      False\n",
       "3316  PUBLISH_YUU               YUUTB_RFM_TAB_4_DATA_AGGR      False\n",
       "3317  PUBLISH_YUU  YUUTB_RFM_TAB_4_DATA_AGGR_BAK_20220629       True\n",
       "3318  PUBLISH_YUU                   YUUTB_RFM_TAB_4_DATA2      False\n",
       "3319         UTIL           ANFIELD_LOY_COMMON_PARAMETERS      False\n",
       "\n",
       "[3320 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_name_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2dc2b02-0c7f-40d2-b452-d0391a55f85a",
   "metadata": {},
   "source": [
    "### 2. Now using REGEX to identify the SP-Table relationships\n",
    "#### We will use the 2 Dataframe we got earlier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82fcb37d-6897-4cf4-a121-ab211c976ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function is used to loop complex pattern like \"INSERT INTO FROM SELECT * FROM xxx\"\n",
    "#Since there can be multiple SELECT FROM tables, Will start from the most outer shell, then move inner\n",
    "#If There is a CREATE TABLE/INSERT TABLE statement, then will get from there\n",
    "def regex_part_analyser(sql_input, regex_type, regex_str, df_master):\n",
    "    str_found  = re.findall(regex_str, sql_input)\n",
    "    str_cat=[]\n",
    "    \n",
    "    while str_found:\n",
    "        sql_input = sql_input.replace(str_found[0], '')\n",
    "        str_cat = str_cat + str_found\n",
    "        str_found  = re.findall(regex_str, sql_input)\n",
    "\n",
    "    df = pd.DataFrame (str_cat, columns = ['TABLE_FULL_NAME'])\n",
    "    df['REGEX_TYPE'] = regex_type\n",
    "    return df\n",
    "\n",
    "def regex_manipulation(sql_input, regex_type, regex_str, opt_df=None, opt_col=None):\n",
    "    output = re.findall(regex_str, sql_input)\n",
    "    output = list(dict.fromkeys(output))\n",
    "    \n",
    "    if opt_df is not None:\n",
    "            output = [x for x in output if x not in opt_df[opt_df.REGEX_TYPE==opt_col]['TABLE_FULL_NAME'].tolist()]\n",
    "\n",
    "    df = pd.DataFrame (output, columns = ['TABLE_FULL_NAME'])\n",
    "    df['REGEX_TYPE'] = regex_type\n",
    "    \n",
    "    return df\n",
    "\n",
    "def isNaN(string):\n",
    "    return string != string\n",
    "\n",
    "\n",
    "def list_main_analyser( sql_df, table_name):\n",
    "\n",
    "    sql_df = sql_df.loc[sql_df['SYNTAX'].str.contains(pat = '\\s+' + table_name + '(?:,|\\)|;| |$){1}', case=False, regex = True)]\n",
    "  #  sql_df['TABLE_NAME'] = table_name\n",
    "    if not sql_df.empty:\n",
    "        sql_df.loc[:, 'TABLE_NAME'] = table_name\n",
    "   # print(sql_df)\n",
    "     \n",
    "    return sql_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67c70304-df4c-437a-964e-dcd4a30def38",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total count of 3320 Table in the file\n",
      "Will loop through each table against the SQL file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3320it [05:49,  9.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COMPLETED : Graph Import File saved to graph_input_sp.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "df_cat = pd.DataFrame()    \n",
    "\n",
    "\n",
    "print(f\"Total count of {len(table_name_df)} Table in the file\")\n",
    "print(f\"Will loop through each table against the SQL file\")\n",
    "    \n",
    "#This will put the SQL Syntax into the main regex code analyser to identify table names\n",
    "for table_name_index, table_name_row in tqdm(table_name_df.iterrows()):\n",
    "    table_string = table_name_row['TABLE_SCHEMA'] + \".\" + table_name_row['TABLE_NAME']\n",
    "    \n",
    "    df_new = list_main_analyser(df, table_string)\n",
    "    \n",
    "    if not df_new.empty:\n",
    "        df_cat = pd.concat([ df_cat, df_new])\n",
    "        \n",
    "            \n",
    "print(\"COMPLETED : Graph Import File saved to graph_input_sp.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7581a62d-e66b-4c1a-bc52-35fc035869eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SP_SCHEMA</th>\n",
       "      <th>SP_NAME</th>\n",
       "      <th>SYNTAX</th>\n",
       "      <th>TABLE_NAME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ANALYSE</td>\n",
       "      <td>HKMN_TO_TX_AGGR_CONSIGNMENT_SALES_BY_DATE_STOR...</td>\n",
       "      <td>CREATE PROC  ANALYSE.HKMN_TO_TX_AGGR_CONSIGNME...</td>\n",
       "      <td>ANALYSE.HKMN_MD_ITEM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ANALYSE</td>\n",
       "      <td>HKMN_TO_TX_AGGR_SALES_BY_DATE_STORE_CATEGORY</td>\n",
       "      <td>CREATE PROC  ANALYSE.HKMN_TO_TX_AGGR_SALES_BY_...</td>\n",
       "      <td>ANALYSE.HKMN_MD_ITEM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ANALYSE</td>\n",
       "      <td>HKMN_TO_TX_SALES_TRANSACTION_COUNT</td>\n",
       "      <td>CREATE PROC  ANALYSE.HKMN_TO_TX_SALES_TRANSACT...</td>\n",
       "      <td>ANALYSE.HKMN_MD_ITEM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>ANALYSE</td>\n",
       "      <td>PCDT2_HK_SUPPLIER_DEAL_TRACKING</td>\n",
       "      <td>CREATE PROC  ANALYSE.PCDT2_HK_SUPPLIER_DEAL_TR...</td>\n",
       "      <td>ANALYSE.HKMN_MD_ITEM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>ANALYSE</td>\n",
       "      <td>PCDT2_HK_SUPPLIER_DEAL_TRACKING_BAK</td>\n",
       "      <td>CREATE PROC  ANALYSE.PCDT2_HK_SUPPLIER_DEAL_TR...</td>\n",
       "      <td>ANALYSE.HKMN_MD_ITEM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>833</th>\n",
       "      <td>PUBLISH</td>\n",
       "      <td>ANFIELD_TO_LOY_POINT_ACT_AND_LIA</td>\n",
       "      <td>CREATE PROC  PUBLISH.ANFIELD_TO_LOY_POINT_ACT_...</td>\n",
       "      <td>UTIL.ANFIELD_LOY_COMMON_PARAMETERS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>835</th>\n",
       "      <td>PUBLISH</td>\n",
       "      <td>ANFIELD_TO_LOY_REWARD_STATUS_ANALYTICS</td>\n",
       "      <td>CREATE PROC  PUBLISH.ANFIELD_TO_LOY_REWARD_STA...</td>\n",
       "      <td>UTIL.ANFIELD_LOY_COMMON_PARAMETERS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>836</th>\n",
       "      <td>PUBLISH</td>\n",
       "      <td>ANFIELD_TO_LOY_REWARD_USE</td>\n",
       "      <td>CREATE PROC  PUBLISH.ANFIELD_TO_LOY_REWARD_USE...</td>\n",
       "      <td>UTIL.ANFIELD_LOY_COMMON_PARAMETERS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>837</th>\n",
       "      <td>PUBLISH</td>\n",
       "      <td>ANFIELD_TO_LOY_SALES_METRICS</td>\n",
       "      <td>CREATE PROC  PUBLISH.ANFIELD_TO_LOY_SALES_METR...</td>\n",
       "      <td>UTIL.ANFIELD_LOY_COMMON_PARAMETERS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850</th>\n",
       "      <td>PUBLISH</td>\n",
       "      <td>ANFIELD_TO_LOY_TRANSACTIONS_BASKET</td>\n",
       "      <td>CREATE PROC  PUBLISH.ANFIELD_TO_LOY_TRANSACTIO...</td>\n",
       "      <td>UTIL.ANFIELD_LOY_COMMON_PARAMETERS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6145 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    SP_SCHEMA                                            SP_NAME  \\\n",
       "13    ANALYSE  HKMN_TO_TX_AGGR_CONSIGNMENT_SALES_BY_DATE_STOR...   \n",
       "14    ANALYSE       HKMN_TO_TX_AGGR_SALES_BY_DATE_STORE_CATEGORY   \n",
       "15    ANALYSE                 HKMN_TO_TX_SALES_TRANSACTION_COUNT   \n",
       "49    ANALYSE                    PCDT2_HK_SUPPLIER_DEAL_TRACKING   \n",
       "50    ANALYSE                PCDT2_HK_SUPPLIER_DEAL_TRACKING_BAK   \n",
       "..        ...                                                ...   \n",
       "833   PUBLISH                   ANFIELD_TO_LOY_POINT_ACT_AND_LIA   \n",
       "835   PUBLISH             ANFIELD_TO_LOY_REWARD_STATUS_ANALYTICS   \n",
       "836   PUBLISH                          ANFIELD_TO_LOY_REWARD_USE   \n",
       "837   PUBLISH                       ANFIELD_TO_LOY_SALES_METRICS   \n",
       "850   PUBLISH                 ANFIELD_TO_LOY_TRANSACTIONS_BASKET   \n",
       "\n",
       "                                                SYNTAX  \\\n",
       "13   CREATE PROC  ANALYSE.HKMN_TO_TX_AGGR_CONSIGNME...   \n",
       "14   CREATE PROC  ANALYSE.HKMN_TO_TX_AGGR_SALES_BY_...   \n",
       "15   CREATE PROC  ANALYSE.HKMN_TO_TX_SALES_TRANSACT...   \n",
       "49   CREATE PROC  ANALYSE.PCDT2_HK_SUPPLIER_DEAL_TR...   \n",
       "50   CREATE PROC  ANALYSE.PCDT2_HK_SUPPLIER_DEAL_TR...   \n",
       "..                                                 ...   \n",
       "833  CREATE PROC  PUBLISH.ANFIELD_TO_LOY_POINT_ACT_...   \n",
       "835  CREATE PROC  PUBLISH.ANFIELD_TO_LOY_REWARD_STA...   \n",
       "836  CREATE PROC  PUBLISH.ANFIELD_TO_LOY_REWARD_USE...   \n",
       "837  CREATE PROC  PUBLISH.ANFIELD_TO_LOY_SALES_METR...   \n",
       "850  CREATE PROC  PUBLISH.ANFIELD_TO_LOY_TRANSACTIO...   \n",
       "\n",
       "                             TABLE_NAME  \n",
       "13                 ANALYSE.HKMN_MD_ITEM  \n",
       "14                 ANALYSE.HKMN_MD_ITEM  \n",
       "15                 ANALYSE.HKMN_MD_ITEM  \n",
       "49                 ANALYSE.HKMN_MD_ITEM  \n",
       "50                 ANALYSE.HKMN_MD_ITEM  \n",
       "..                                  ...  \n",
       "833  UTIL.ANFIELD_LOY_COMMON_PARAMETERS  \n",
       "835  UTIL.ANFIELD_LOY_COMMON_PARAMETERS  \n",
       "836  UTIL.ANFIELD_LOY_COMMON_PARAMETERS  \n",
       "837  UTIL.ANFIELD_LOY_COMMON_PARAMETERS  \n",
       "850  UTIL.ANFIELD_LOY_COMMON_PARAMETERS  \n",
       "\n",
       "[6145 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37455a56-4815-4cd2-983b-61fa3f138b80",
   "metadata": {},
   "source": [
    "### Export the results into 3. OUTPUT_GRAPH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39dd3eea-e1f1-4c1d-8136-a1675737cd28",
   "metadata": {},
   "source": [
    "#### We will add back the remaining SP Name that have not been matched into the Output csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "053e8762-68b9-44bb-95dd-68389fd7ea5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This checks if there are any left out scripts without TABLE name\n",
    "delta_df = pd.merge(df, df_cat, how='left', left_on=['SP_SCHEMA','SP_NAME'], right_on = ['SP_SCHEMA','SP_NAME'])\n",
    "#delta_df.drop(columns=[\"SYNTAX\"], inplace=True)\n",
    "delta_df['TABLE_FULL_NAME']=delta_df['TABLE_NAME'].apply(lambda x: final_table_name_cleansing(x))\n",
    "delta_df = delta_df.applymap(lambda s: s.upper() if type(s) == str else s)\n",
    "\n",
    "#delta_df\n",
    "#delta_df.to_excel(f\"checkin1.xlsx\")\n",
    "delta_df['SYNTAX'] = delta_df['SYNTAX_x']\n",
    "delta_df.drop(columns=[\"SYNTAX_y\", \"SYNTAX_x\"], inplace=True)\n",
    "\n",
    "delta_df.drop(columns=[\"SYNTAX\"], inplace=True)\n",
    "delta_df.to_csv(graph_ingestion_sp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "33553aae-387c-474d-99fe-3e91bfc1a7a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SP_SCHEMA</th>\n",
       "      <th>SP_NAME</th>\n",
       "      <th>TABLE_NAME</th>\n",
       "      <th>TABLE_FULL_NAME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ANALYSE</td>\n",
       "      <td>ADF_RAISE_EXCEPTION</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ANALYSE</td>\n",
       "      <td>ANFIELD_TO_INGESTION_SUMMARY</td>\n",
       "      <td>ANALYSE.ANFIELD_INGESTION_SUMMARY</td>\n",
       "      <td>ANALYSE.ANFIELD_INGESTION_SUMMARY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ANALYSE</td>\n",
       "      <td>ANFIELD_TO_INGESTION_SUMMARY</td>\n",
       "      <td>ANALYSE.ANFIELD_MD_LOCATION</td>\n",
       "      <td>ANALYSE.ANFIELD_MD_LOCATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ANALYSE</td>\n",
       "      <td>ANFIELD_TO_INGESTION_SUMMARY</td>\n",
       "      <td>ANALYSE.ANFIELD_MD_MEMBER_ACCOUNT</td>\n",
       "      <td>ANALYSE.ANFIELD_MD_MEMBER_ACCOUNT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ANALYSE</td>\n",
       "      <td>ANFIELD_TO_INGESTION_SUMMARY</td>\n",
       "      <td>ANALYSE.ANFIELD_MD_MEMBER_CLUB</td>\n",
       "      <td>ANALYSE.ANFIELD_MD_MEMBER_CLUB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6212</th>\n",
       "      <td>PUBLISH_YUU</td>\n",
       "      <td>YUUTB_RFM_TAB_4_SP_MONTHENDUPDATE_AGGR</td>\n",
       "      <td>PUBLISH_YUU.YUUTB_RFM_TAB_4_DATA_AGGR</td>\n",
       "      <td>PUBLISH_YUU.YUUTB_RFM_TAB_4_DATA_AGGR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6213</th>\n",
       "      <td>UTIL</td>\n",
       "      <td>ANFIELD_LOY_PARAMETERS</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6214</th>\n",
       "      <td>UTIL</td>\n",
       "      <td>CREATE_OR_REPLACE_TBL</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6215</th>\n",
       "      <td>UTIL</td>\n",
       "      <td>DROP_TBL_IF_EXISTS</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6216</th>\n",
       "      <td>UTIL</td>\n",
       "      <td>GET_TABLE_SIZE_SQLDW</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6217 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        SP_SCHEMA                                 SP_NAME  \\\n",
       "0         ANALYSE                     ADF_RAISE_EXCEPTION   \n",
       "1         ANALYSE            ANFIELD_TO_INGESTION_SUMMARY   \n",
       "2         ANALYSE            ANFIELD_TO_INGESTION_SUMMARY   \n",
       "3         ANALYSE            ANFIELD_TO_INGESTION_SUMMARY   \n",
       "4         ANALYSE            ANFIELD_TO_INGESTION_SUMMARY   \n",
       "...           ...                                     ...   \n",
       "6212  PUBLISH_YUU  YUUTB_RFM_TAB_4_SP_MONTHENDUPDATE_AGGR   \n",
       "6213         UTIL                  ANFIELD_LOY_PARAMETERS   \n",
       "6214         UTIL                   CREATE_OR_REPLACE_TBL   \n",
       "6215         UTIL                      DROP_TBL_IF_EXISTS   \n",
       "6216         UTIL                    GET_TABLE_SIZE_SQLDW   \n",
       "\n",
       "                                 TABLE_NAME  \\\n",
       "0                                       NaN   \n",
       "1         ANALYSE.ANFIELD_INGESTION_SUMMARY   \n",
       "2               ANALYSE.ANFIELD_MD_LOCATION   \n",
       "3         ANALYSE.ANFIELD_MD_MEMBER_ACCOUNT   \n",
       "4            ANALYSE.ANFIELD_MD_MEMBER_CLUB   \n",
       "...                                     ...   \n",
       "6212  PUBLISH_YUU.YUUTB_RFM_TAB_4_DATA_AGGR   \n",
       "6213                                    NaN   \n",
       "6214                                    NaN   \n",
       "6215                                    NaN   \n",
       "6216                                    NaN   \n",
       "\n",
       "                            TABLE_FULL_NAME  \n",
       "0                                            \n",
       "1         ANALYSE.ANFIELD_INGESTION_SUMMARY  \n",
       "2               ANALYSE.ANFIELD_MD_LOCATION  \n",
       "3         ANALYSE.ANFIELD_MD_MEMBER_ACCOUNT  \n",
       "4            ANALYSE.ANFIELD_MD_MEMBER_CLUB  \n",
       "...                                     ...  \n",
       "6212  PUBLISH_YUU.YUUTB_RFM_TAB_4_DATA_AGGR  \n",
       "6213                                         \n",
       "6214                                         \n",
       "6215                                         \n",
       "6216                                         \n",
       "\n",
       "[6217 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ac2caf0d-4aa9-4524-92f9-d48724123799",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_name_df.to_csv(graph_ingestion_table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Graph",
   "language": "python",
   "name": "graph"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
